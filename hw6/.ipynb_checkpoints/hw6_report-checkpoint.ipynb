{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS189 : Introduction to Machine Learning\n",
    "## Homework 6\n",
    "### SID : 23274190  Name : Hye Soo Choi\n",
    "\n",
    "#### Neural Networks for MNIST Digit Recognition\n",
    "In this homework, we will implement neural networks to classify handwritten digits using raw pixels as features. We will be using the MNIST digits dataset that you used in previous homework assignments. The state-of-the-art error rate on this dataset using deep convolutional neural networks is around 0.5%. For this assignment, we should, with appropriate parameter settings, get approximately or better than 6% error using a neural network with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "We import the data and transform each label between 0 and 9 to a vector of length $10$ which has single $1$ in the position of true class and $0$ everywhere else. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = sio.loadmat('./dataset/train.mat')\n",
    "test_data = sio.loadmat('./dataset/test.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-a29310b64561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtr_lb_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtr_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "tr_img = train_data['train_images']\n",
    "tr_lb_num = train_data['train_labels'][:,0]\n",
    "tr_img = np.reshape(tr_img, (784, 60000), order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_lb_num = train_data['train_labels'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_img = np.reshape(np.transpose(test_data['test_images']), (784, 10000), order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_img = np.append(tr_img, ts_img, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_lb = np.zeros((len(tr_lb),10))\n",
    "\n",
    "for i in np.arange(len(tr_lb)):\n",
    "    j = tr_lb_num[i]\n",
    "    temp_lb[i,j] = 1\n",
    "\n",
    "tr_lb = temp_lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we normalize, or standardize, all feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_img = all_img.astype(float) # change data type from int to float, in order to \n",
    "                                # facilitate calculations for standardization\n",
    "all_img = preprocessing.scale(all_img, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seperating into training data and validation data\n",
    "\n",
    "We use 50,000 training points and 10,000 validation for the reported train/validation accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_img = all_img[:, 60000:70000]\n",
    "tr_img = all_img[:, 0:60000]\n",
    "valid_ind = nr.choice(60000, 10000, replace = False)\n",
    "vd_img = tr_img[: , valid_ind]\n",
    "tr_img = tr_img[:, np.setdiff1d(np.arange(60000), valid_ind)]\n",
    "vd_lb = tr_lb[valid_ind, :]\n",
    "tr_lb = tr_lb[np.setdiff1d(np.arange(60000), valid_ind), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vd_lb_num = tr_lb_num[valid_ind]\n",
    "tr_lb_num = tr_lb_num [np.setdiff1d(np.arange(60000), valid_ind)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network\n",
    "In this assignment, we are asked to implement a neural network with one hidden layer.\n",
    "1.  We will be using a hidden layer of size 200. Let $n_{in} = 784$, the number of features for the digits class. Let $n_{hid} = 200$, the size of the hidden layer. Finally, let $n_{out}$ = 10, the number of classes. Then, we will have $n_{in} + 1$ units in the input layer, $n_{hid} + 1$ units in the hidden layer, and $n_{out}$ units in the output layer. The input and hidden layers have one additional unit which always takes a value of $1$ to represent bias. The output layer size is set to the number of classes. Each label will have to be transformed to a vector of length $10$ which has a single $1$ in the position of the true class and $0$ everywhere else.\n",
    "\n",
    "2. The parameters of this model are the following:\n",
    "-  $V$ , a $n_{hid}$-by-($n_{in} + 1$) matrix where the $(i; j)$-entry represents the weight connecting the $j$-th unit in the input layer to the $i$-th unit in the hidden layer. The $i$-th row of $V$ represents the ensemble of weights feeding into the $i$-th hidden unit. Note: there is an additional row for weights connecting the bias term to each unit in the hidden layer.\n",
    "- $W$, a $n_{out}$-by-($n_{hid} + 1$) matrix where the (i; j)-entry represents the weight connecting the j-th unit in the hidden layer to the i-th unit in the output layer. The i-th row of W represents the ensemble of weights feeding into the $i$-th output unit. Note: again there is an additional row for weights connecting the bias term to each unit in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization of Weights\n",
    "\n",
    "We initialize your weights with random values. This allows us to break\n",
    "symmetry that occurs when all weights are initialized to 0. Some ways to do this are to initialize by drawing values from a uniform distribution from [􀀀$-\\epsilon$, 􀀀$\\epsilon$] or from a Gaussian distribution with mean 0 and variance 􀀀$\\epsilon^2$ where 􀀀$\\epsilon$ is some small fixed constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr.seed(0)\n",
    "n_in = 784\n",
    "n_hid = 200\n",
    "n_out = 10\n",
    "epsilon = 0.01\n",
    "V0 = nr.normal(scale = epsilon, size = (n_hid, n_in + 1))\n",
    "W0 = nr.normal(scale = epsilon, size = (n_out, n_hid + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding one additional unit which always takes a value of 1 to represent bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bias(mat):\n",
    "    if len(mat.shape) > 1:\n",
    "        ncol = mat.shape[1]\n",
    "        temp = np.array([[1.0 for j in range(ncol)]])\n",
    "        mat = np.append(mat, temp, axis = 0)\n",
    "    else:\n",
    "        mat = np.append(mat, [1.0], axis = 0)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_img = add_bias(tr_img) # add one column of 1's to all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 50000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two loss functions : Mean-Squared Error and Cross-Entropy Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared(true, pred):\n",
    "    temp = np.square(true - pred)\n",
    "    err = np.sum(temp)\n",
    "    return err/2\n",
    "\n",
    "def cross_entropy(true, pred):\n",
    "    n,k = true.shape\n",
    "    ind = (true == 1)\n",
    "    temp = np.sum(true[ind] * np.log(pred[ind])) + np.sum((1-true[~ind]) * np.log(1-pred[~ind]))\n",
    "    err = - temp\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9353285217470635"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(tr_lb[1:2,],predict(V0,W0, tr_img[:,1:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use tanh activation function for the hidden layer units and the sigmoid function for the output layer units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "   \n",
    "def sigmoid_stb(mat):\n",
    "    # Numerically-stable sigmoid function\n",
    "    \n",
    "    ind = (mat >= 0)\n",
    "    temp = np.zeros(mat.shape)\n",
    "    temp[ind] = 1/(1+np.exp(-mat[ind]))\n",
    "    z =np.exp(mat[~ind])\n",
    "    temp[~ind] = z /(1+z)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "def sigmoid(mat):\n",
    "    temp = 1/(1+ np.exp(- mat))\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the loss for coefficient matrices W and V \n",
    "\n",
    "Here we implement a fuction that takes in two coefficient matrices W and V, and returns the values of output units when we use two matrices W and V as coefficients of linear combination for the hidden layer units and for the output layer units, respectively, to train neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict( V,W, img):\n",
    "    temp = np.dot(V, img)\n",
    "    hidden = np.tanh(temp)\n",
    "    hidden = add_bias(hidden)\n",
    "    temp = np.dot(W, hidden)\n",
    "    return np.transpose(sigmoid_stb(temp))\n",
    "\n",
    "def calculate_loss(V,W, img, true_label, loss_fun):\n",
    "    pred_label = predict(V, W, img)\n",
    "    loss = loss_fun(true_label, pred_label)\n",
    "    return loss\n",
    "\n",
    "def misclassification(V,W,img, true_num):\n",
    "    pred = predict(V,W,img)\n",
    "    pred_num = np.argmax(pred, axis = 1)\n",
    "    return np.sum(pred_num != true_num)/len(true_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back propagation in Stochastic Gradient Descent\n",
    "The procedure of matrix $V$ influencing on the final output and thus the total mean squared error can be divided into several steps as follows:\n",
    "$$\n",
    "V \\mapsto A = Vx \\mapsto B = \\tanh(A) \\mapsto C = WB^* \\mapsto D = sigmoid(C) \\mapsto E =\\frac{1}{2}||Y-D||_2^2.\n",
    "$$\n",
    "Therefore, stepwise,\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E}{\\partial D} &= (D - Y),\\\\\n",
    "\\frac{\\partial D}{\\partial C} &= diag(D)(I-diag(D)),\\\\\n",
    "\\frac{\\partial C}{\\partial B} &= W^\\top,\\\\\n",
    "\\frac{\\partial B}{\\partial A} &= I - diag(B^2),\\\\\n",
    "\\frac{\\partial A}{\\partial V_j} &= diag(x_j),\\\\\n",
    "\\frac{\\partial C}{\\partial W_j} &= diag(B^*_j)\\\\\n",
    "\\end{align*}\n",
    "where $x$ is a $(n_{in} + 1)$-dim column vector, $V_j,W_j$ denotes the $j$th column of the matrix $V, W$, respectively, $B^*$ is the matrix that results from adding a row of $1$ to $B$. In case we use cross-entropy instead, \n",
    "$$\n",
    "\\frac{\\partial E}{\\partial D} = Y/D - (1-Y)/(1-D)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_gradient(V,W, i, loss_fun_name):\n",
    "    \n",
    "    x = tr_img[:,i:i+1]\n",
    "    y = np.transpose(tr_lb[i:i+1,:])\n",
    "    A = np.dot(V, x)\n",
    "    B = np.tanh(A)\n",
    "    B_bias = add_bias(B)\n",
    "    C = np.dot(W, B_bias)\n",
    "    D = sigmoid_stb(C)\n",
    "\n",
    "    I = np.identity(n_out)\n",
    "    if loss_fun_name == 'mean_squared':\n",
    "        dEdD = - y + D\n",
    "    elif loss_fun_name == 'cross_entropy':\n",
    "        ind = (y == 1)\n",
    "        temp = np.zeros(y.shape)\n",
    "        temp[ind] = - y[ind]/D[ind]\n",
    "        temp[~ind] = (1-y[~ind])/(1-D[~ind])\n",
    "        dEdD = temp\n",
    "        \n",
    "\n",
    "    dDdC = np.multiply(D, 1-D)\n",
    "    dCdB = np.transpose(W[:, :n_hid])\n",
    "    dBdA = 1- np.square(B)\n",
    "    \n",
    "    dEdC = np.multiply(dDdC, dEdD)\n",
    "    dEdB = np.dot(dCdB, dEdC)\n",
    "    dEdA = np.multiply(dBdA, dEdB)\n",
    "    dEdV = np.array([])\n",
    "    dEdW = np.array([])\n",
    " \n",
    "    \n",
    "    dAdV = x[:,0]\n",
    "    dEdV = np.outer(dEdA[:,0], dAdV)\n",
    "\n",
    "    dCdW = B_bias[:,0]\n",
    "    dEdW = np.outer(dEdC[:,0], dCdW)\n",
    "\n",
    "        \n",
    "    return np.concatenate((dEdV.ravel('F'), dEdW.ravel('F')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = find_gradient(V0, W0, 2, 'mean_squared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = find_gradient(V0, W0, 2, 'cross_entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def column_to_matrix(vec, r, c):\n",
    "    return vec.reshape((r,c), order = 'F')\n",
    "    \n",
    "def matrix_to_column(mat):\n",
    "    return mat.ravel(order = 'F')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Gradient Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def numerical_gradient(V, W, i, eps = 1e-8):\n",
    "    grad = np.concatenate((matrix_to_column(V), matrix_to_column(W)))\n",
    "\n",
    "    num_grad = np.zeros(grad.shape)\n",
    "    temp = grad\n",
    "    for j in range(len(grad)):\n",
    "        \n",
    "        temp[j] = grad[j] + eps\n",
    "        V_temp = column_to_matrix(temp[0:n_hid*(n_in + 1)], n_hid, n_in + 1)\n",
    "        W_temp = column_to_matrix(temp[n_hid*(n_in + 1):], n_out, n_hid + 1)\n",
    "        loss1 = calculate_loss(V_temp,W_temp, tr_img[:, i:i+1], tr_lb[i:i+1,:], mean_squared)\n",
    "        \n",
    "\n",
    "        temp[j] = grad[j] - 2 * eps\n",
    "        V_temp = column_to_matrix(temp[0:n_hid*(n_in + 1)], n_hid, n_in + 1)\n",
    "        W_temp = column_to_matrix(temp[n_hid*(n_in + 1):], n_out, n_hid + 1)\n",
    "        loss2 = calculate_loss(V_temp,W_temp, tr_img[:, i:i+1],tr_lb[i:i+1,:], mean_squared)\n",
    "        \n",
    "        num_grad[j] = (loss1-loss2)/(2*eps)\n",
    "        temp = grad\n",
    "        \n",
    "    return num_grad\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_grad = numerical_gradient(V0, W0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def norm(l):\n",
    "    return np.sqrt(np.sum(np.square(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7624782661673705e-06"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(a-num_grad)/norm(a + num_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_gradient_cross_entropy(V, W, i, eps = 1e-8):\n",
    "    grad = np.concatenate((matrix_to_column(V), matrix_to_column(W)))\n",
    "\n",
    "    num_grad = np.zeros(grad.shape)\n",
    "    temp = grad\n",
    "    for j in range(len(grad)):\n",
    "        \n",
    "        temp[j] = grad[j] + eps\n",
    "        V_temp = column_to_matrix(temp[0:n_hid*(n_in + 1)], n_hid, n_in + 1)\n",
    "        W_temp = column_to_matrix(temp[n_hid*(n_in + 1):], n_out, n_hid + 1)\n",
    "        loss1 = calculate_loss(V_temp,W_temp, tr_img[:, i:i+1], tr_lb[i:i+1,:], cross_entropy)\n",
    "        \n",
    "\n",
    "        temp[j] = grad[j] - 2 * eps\n",
    "        V_temp = column_to_matrix(temp[0:n_hid*(n_in + 1)], n_hid, n_in + 1)\n",
    "        W_temp = column_to_matrix(temp[n_hid*(n_in + 1):], n_out, n_hid + 1)\n",
    "        loss2 = calculate_loss(V_temp,W_temp, tr_img[:, i:i+1],tr_lb[i:i+1,:], cross_entropy)\n",
    "        \n",
    "        num_grad[j] = (loss1-loss2)/(2*eps)\n",
    "        temp = grad\n",
    "        \n",
    "    return num_grad\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_grad_cross = numerical_gradient_cross_entropy(V0, W0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.798625244755789e-06"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(b-num_grad_cross)/norm(b+num_grad_cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proves that our way to find a gradient actually did its job pretty well.\n",
    "\n",
    "#### Train Neural Network by Stochastic gradient descent using Mean Squared loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(V, W, img, true, step):\n",
    "    n = len(true)\n",
    "    ind = nr.choice(n, n, replace = False)\n",
    "    V_temp = V\n",
    "    W_temp = W\n",
    "\n",
    "    VW_temp = np.concatenate((matrix_to_column(V), matrix_to_column(W)))\n",
    "\n",
    "    \n",
    "    for i in ind:\n",
    "        grad = find_gradient(V_temp,W_temp, i, 'mean_squared')\n",
    "        VW_temp = VW_temp - step * grad\n",
    "        \n",
    "\n",
    "    return (V_temp, W_temp)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Neural Network by Stochastic gradient descent using Cross-entropy loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_cross_entropy(V, W, img, true, index, start, end, step):\n",
    "    n = len(true)\n",
    "\n",
    "    V_temp = V\n",
    "    W_temp = W\n",
    "\n",
    "    \n",
    "    VW_temp = np.concatenate((matrix_to_column(V), matrix_to_column(W)))\n",
    "    \n",
    "    for i in index[start * 1000 : end * 1000]:\n",
    "        grad = find_gradient(V_temp,W_temp, i, 'cross_entropy')\n",
    "        VW_temp = VW_temp - step * grad\n",
    "        V_temp = column_to_matrix(VW_temp[0:n_hid*(n_in + 1)], n_hid, n_in + 1)\n",
    "        W_temp = column_to_matrix(VW_temp[n_hid*(n_in + 1):], n_out, n_hid + 1)\n",
    "\n",
    "    return (V_temp, W_temp)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 40929.7207341\n",
      "1 : 30919.863594\n",
      "2 : 25210.3998269\n",
      "3 : 19617.1455284\n",
      "4 : 19978.4905853\n",
      "5 : 15535.5047449\n",
      "6 : 14941.930507\n",
      "7 : 14549.8250461\n",
      "8 : 13352.3201274\n",
      "9 : 13019.6248243\n",
      "10 : 11819.2054932\n",
      "11 : 10737.4617504\n",
      "12 : 10472.0429109\n",
      "13 : 10584.1127487\n",
      "14 : 9445.36606802\n",
      "15 : 9185.59786763\n",
      "16 : 9587.57847501\n",
      "17 : 9033.25093584\n",
      "18 : 8746.21794187\n",
      "19 : 8430.37232232\n",
      "20 : 8319.67534463\n",
      "21 : 7985.80457463\n",
      "22 : 7879.50913551\n",
      "23 : 7945.11128709\n",
      "24 : 7909.94333898\n",
      "25 : 7613.05979041\n",
      "26 : 7543.93025939\n",
      "27 : 7225.68056364\n",
      "28 : 7039.57881143\n",
      "29 : 7312.09177147\n",
      "30 : 7286.55141191\n",
      "31 : 7223.99054767\n",
      "32 : 6907.16692561\n",
      "33 : 6770.77727944\n",
      "34 : 6967.78088041\n",
      "35 : 6994.37608829\n",
      "36 : 6753.22096898\n",
      "37 : 6309.90442219\n",
      "38 : 6517.28229107\n",
      "39 : 6405.37610717\n",
      "40 : 6395.6374105\n",
      "41 : 6221.81380074\n",
      "42 : 6305.94040168\n",
      "43 : 6156.15985791\n",
      "44 : 5966.26074138\n",
      "45 : 5833.42905317\n",
      "46 : 5864.27592939\n",
      "47 : 6108.95630715\n",
      "48 : 6268.94687916\n",
      "49 : 6225.00257663\n",
      "50 : 6022.1553757\n",
      "51 : 5971.17301981\n",
      "52 : 5820.6534213\n",
      "53 : 6032.54446376\n",
      "54 : 6049.46620942\n",
      "55 : 5803.12452206\n",
      "56 : 5792.20228176\n",
      "57 : 5820.37824958\n",
      "58 : 5605.54300466\n",
      "59 : 5458.41881985\n",
      "60 : 5506.35830411\n",
      "61 : 5399.93019142\n",
      "62 : 5514.46605886\n",
      "63 : 5622.44541861\n",
      "64 : 5306.07657945\n",
      "65 : 5283.18700455\n",
      "66 : 5403.36501559\n",
      "67 : 5442.42660564\n",
      "68 : 5420.98021216\n",
      "69 : 5249.89274238\n",
      "70 : 5131.86629273\n",
      "71 : 5081.63683797\n",
      "72 : 5078.12905896\n",
      "73 : 5228.67571065\n",
      "74 : 5096.65300389\n",
      "75 : 5027.37723071\n",
      "76 : 5074.43870539\n",
      "77 : 5002.7227176\n",
      "78 : 5096.70886598\n",
      "79 : 5021.57331447\n",
      "80 : 4932.50268443\n",
      "81 : 4788.66439414\n",
      "82 : 4971.88706639\n",
      "83 : 4905.00723041\n",
      "84 : 4907.72410022\n",
      "85 : 4878.31149476\n",
      "86 : 4805.11006068\n",
      "87 : 4948.29537613\n",
      "88 : 4746.22101906\n",
      "89 : 4856.06831904\n",
      "90 : 4860.99607069\n",
      "91 : 4790.47738631\n",
      "92 : 4738.97331756\n",
      "93 : 4736.67321585\n",
      "94 : 4664.39333916\n",
      "95 : 4570.21350738\n",
      "96 : 4609.89595202\n",
      "97 : 4600.64546538\n",
      "98 : 4554.31337327\n",
      "99 : 4611.20887501\n",
      "100 : 4490.3007937\n",
      "101 : 4675.25708964\n",
      "102 : 4474.84837502\n",
      "103 : 4338.51799077\n",
      "104 : 4173.64401882\n",
      "105 : 4253.80796134\n",
      "106 : 4338.57800127\n",
      "107 : 4196.05847962\n",
      "108 : 4443.63160415\n",
      "109 : 4558.11158981\n",
      "110 : 4466.53452001\n",
      "111 : 4686.74280708\n",
      "112 : 4661.3986673\n",
      "113 : 4362.60600499\n",
      "114 : 4299.10127165\n",
      "115 : 4269.42185939\n",
      "116 : 4259.12459209\n",
      "117 : 4296.53627134\n",
      "118 : 4428.61130345\n",
      "119 : 4266.08227314\n",
      "120 : 4022.49139426\n",
      "121 : 4144.51401976\n",
      "122 : 4135.88916089\n",
      "123 : 4272.47720967\n",
      "124 : 4182.40663582\n",
      "125 : 4390.54119942\n",
      "126 : 4375.8438877\n",
      "127 : 3955.17223904\n",
      "128 : 4292.76366195\n",
      "129 : 4130.64244978\n",
      "130 : 4155.30239071\n",
      "131 : 4003.55887029\n",
      "132 : 4073.25430633\n",
      "133 : 3850.16559735\n",
      "134 : 4072.13785875\n",
      "135 : 4017.7929853\n",
      "136 : 3904.48175655\n",
      "137 : 4000.12483766\n",
      "138 : 4013.80648815\n",
      "139 : 3950.29324464\n",
      "140 : 3862.93649431\n",
      "141 : 3806.33640751\n",
      "142 : 3912.1576251\n",
      "143 : 3971.28852597\n",
      "144 : 3944.37007519\n",
      "145 : 3773.06708712\n",
      "146 : 3754.45315504\n",
      "147 : 3766.43369557\n",
      "148 : 3733.69578007\n",
      "149 : 3644.53410085\n",
      "150 : 3727.76425495\n",
      "151 : 3666.24395459\n",
      "152 : 3541.336812\n",
      "153 : 3807.34680305\n",
      "154 : 3683.37107208\n",
      "155 : 3567.35896704\n",
      "156 : 3504.62212243\n",
      "157 : 3596.41299647\n",
      "158 : 3537.11883656\n",
      "159 : 3576.66990949\n",
      "160 : 3549.55629222\n",
      "161 : 3669.38265462\n",
      "162 : 3683.31620063\n",
      "163 : 3879.45826476\n",
      "164 : 3716.40396331\n",
      "165 : 3617.29939497\n",
      "166 : 3749.19316149\n",
      "167 : 3602.6472783\n",
      "168 : 3489.6738796\n",
      "169 : 3713.29264817\n",
      "170 : 3787.80857338\n",
      "171 : 3477.78494056\n",
      "172 : 3566.15189975\n",
      "173 : 3745.22380047\n",
      "174 : 3674.57792901\n",
      "175 : 3460.48345186\n",
      "176 : 3462.58637051\n",
      "177 : 3492.09753046\n",
      "178 : 3581.82194716\n",
      "179 : 3515.7825011\n",
      "180 : 3659.31447948\n",
      "181 : 3425.09436144\n",
      "182 : 3399.33234427\n",
      "183 : 3404.97381171\n",
      "184 : 3547.84196064\n",
      "185 : 3386.49151428\n",
      "186 : 3348.57698209\n",
      "187 : 3358.74753023\n",
      "188 : 3381.90054491\n",
      "189 : 3400.59172822\n",
      "190 : 3324.05708515\n",
      "191 : 3291.39849637\n",
      "192 : 3476.24154008\n",
      "193 : 3347.90096337\n",
      "194 : 3453.56935248\n",
      "195 : 3486.88118277\n",
      "196 : 3353.89046329\n",
      "197 : 3458.27061325\n",
      "198 : 3354.81892731\n",
      "199 : 3286.83599353\n",
      "200 : 3307.5162236\n",
      "201 : 3279.53343267\n",
      "202 : 3504.7935389\n",
      "203 : 3375.95718978\n",
      "204 : 3201.97512168\n",
      "205 : 3148.47009202\n",
      "206 : 3283.51918639\n",
      "207 : 3481.89067119\n",
      "208 : 3310.53609892\n",
      "209 : 3255.09412281\n",
      "210 : 3275.31758658\n",
      "211 : 3212.29660487\n",
      "212 : 3410.677727\n",
      "213 : 3220.79815087\n",
      "214 : 3140.1802825\n",
      "215 : 3138.92991285\n",
      "216 : 3217.68300907\n",
      "217 : 3344.64572543\n",
      "218 : 3192.09816235\n",
      "219 : 3384.90622477\n",
      "220 : 3169.26509684\n",
      "221 : 3317.76953059\n",
      "222 : 3249.53241292\n",
      "223 : 3075.27211674\n",
      "224 : 3142.1286951\n",
      "225 : 3125.00942522\n",
      "226 : 3201.21795539\n",
      "227 : 3056.08028193\n",
      "228 : 3002.75206095\n",
      "229 : 3053.23084892\n",
      "230 : 2945.70604849\n",
      "231 : 3092.54148142\n",
      "232 : 3135.79230648\n",
      "233 : 3277.76419458\n",
      "234 : 3132.6700701\n",
      "235 : 3123.8471955\n",
      "236 : 2963.82378233\n",
      "237 : 3148.8044837\n",
      "238 : 3012.12015273\n",
      "239 : 3148.27040085\n",
      "240 : 3199.89912255\n",
      "241 : 2935.19573569\n",
      "242 : 2922.73872248\n",
      "243 : 2831.10593614\n",
      "244 : 2886.45858422\n",
      "245 : 2841.5169174\n",
      "246 : 2931.36718298\n",
      "247 : 2959.37791346\n",
      "248 : 2972.38339697\n",
      "249 : 2940.93904983\n",
      "250 : 2858.9583869\n",
      "251 : 3017.66148582\n",
      "252 : 2910.10465836\n",
      "253 : 3041.37665818\n",
      "254 : 3143.017829\n",
      "255 : 2986.57846444\n",
      "256 : 3073.41845827\n",
      "257 : 2972.75777404\n",
      "258 : 2894.68196446\n",
      "259 : 2869.83014638\n",
      "260 : 3059.26508372\n",
      "261 : 2942.08316408\n",
      "262 : 2958.13040155\n",
      "263 : 2850.41591936\n",
      "264 : 2919.9755513\n",
      "265 : 2822.89786993\n",
      "266 : 2782.71671381\n",
      "267 : 2770.11765153\n",
      "268 : 2872.71112781\n",
      "269 : 3075.93382348\n",
      "270 : 2889.74652344\n",
      "271 : 2841.23919198\n",
      "272 : 2898.02377413\n",
      "273 : 2876.39999078\n",
      "274 : 3084.96284247\n",
      "275 : 3070.65777664\n",
      "276 : 2817.68099314\n",
      "277 : 2945.33810834\n",
      "278 : 2930.38339575\n",
      "279 : 2850.35276466\n",
      "280 : 2812.36719705\n",
      "281 : 2801.19640093\n",
      "282 : 2862.52830061\n",
      "283 : 2872.55474213\n",
      "284 : 2848.59063453\n",
      "285 : 2821.64857408\n",
      "286 : 2825.63810264\n",
      "287 : 2856.02106187\n",
      "288 : 2678.63521121\n",
      "289 : 2690.73767581\n",
      "290 : 2663.52195874\n",
      "291 : 2717.45468038\n",
      "292 : 2746.25849203\n",
      "293 : 2767.76033087\n",
      "294 : 2759.71322433\n",
      "295 : 2861.0706848\n",
      "296 : 2704.07457113\n",
      "297 : 2763.72140189\n",
      "298 : 2691.58694964\n",
      "299 : 2923.4570165\n",
      "300 : 2945.24766972\n",
      "301 : 2693.50902561\n",
      "302 : 2627.58981217\n",
      "303 : 2625.18539296\n",
      "304 : 2605.50705217\n",
      "305 : 2565.52715553\n",
      "306 : 2686.66634314\n",
      "307 : 2710.73069608\n",
      "308 : 2851.41265321\n",
      "309 : 2620.46203194\n",
      "310 : 2734.44023828\n",
      "311 : 2631.66436866\n",
      "312 : 2748.58760281\n",
      "313 : 2727.31265364\n",
      "314 : 2696.17197448\n",
      "315 : 2850.07260383\n",
      "316 : 2652.76644974\n",
      "317 : 2662.52410424\n",
      "318 : 2571.91351929\n",
      "319 : 2545.66705299\n",
      "320 : 2581.21133723\n",
      "321 : 2621.94947825\n",
      "322 : 2706.2383739\n",
      "323 : 2734.12128662\n",
      "324 : 2672.53491552\n",
      "325 : 2587.95560139\n",
      "326 : 2573.96455078\n",
      "327 : 2506.07195509\n",
      "328 : 2561.49337703\n",
      "329 : 2639.61894158\n",
      "330 : 2645.2336862\n",
      "331 : 2652.29698123\n",
      "332 : 2599.33296143\n",
      "333 : 2576.95490138\n",
      "334 : 2576.39210755\n",
      "335 : 2561.22341806\n",
      "336 : 2529.49291363\n",
      "337 : 2530.80812661\n",
      "338 : 2596.87008922\n",
      "339 : 2565.22335741\n",
      "340 : 2656.34363798\n",
      "341 : 2696.71616212\n",
      "342 : 2527.68407789\n",
      "343 : 2481.31674303\n",
      "344 : 2477.37834779\n",
      "345 : 2460.52564018\n",
      "346 : 2514.48690878\n",
      "347 : 2480.19492819\n",
      "348 : 2406.48231451\n",
      "349 : 2419.67365698\n",
      "350 : 2453.10978573\n",
      "351 : 2440.30459897\n",
      "352 : 2550.97277562\n",
      "353 : 2548.11331371\n",
      "354 : 2533.88098964\n",
      "355 : 2570.59741363\n",
      "356 : 2540.19099392\n",
      "357 : 2591.81696896\n",
      "358 : 2510.77911794\n",
      "359 : 2502.8593874\n",
      "360 : 2458.54565887\n",
      "361 : 2710.22308404\n",
      "362 : 2622.02759251\n",
      "363 : 2423.75440818\n",
      "364 : 2434.98023585\n",
      "365 : 2476.67164549\n",
      "366 : 2583.05427065\n",
      "367 : 2690.94080426\n",
      "368 : 2487.25923736\n",
      "369 : 2405.25569931\n",
      "370 : 2358.83685615\n",
      "371 : 2479.76980846\n",
      "372 : 2579.88026762\n",
      "373 : 2498.35716183\n",
      "374 : 2516.67255784\n",
      "375 : 2411.96014121\n",
      "376 : 2459.06357813\n",
      "377 : 2476.42939246\n",
      "378 : 2515.44713315\n",
      "379 : 2428.95255677\n",
      "380 : 2335.62407532\n",
      "381 : 2315.11905304\n",
      "382 : 2404.1145626\n",
      "383 : 2292.41591641\n",
      "384 : 2287.71848981\n",
      "385 : 2331.87878032\n",
      "386 : 2403.58690546\n",
      "387 : 2411.47328958\n",
      "388 : 2305.15119263\n",
      "389 : 2300.8907884\n",
      "390 : 2389.08091941\n",
      "391 : 2387.52770718\n",
      "392 : 2366.2947985\n",
      "393 : 2468.25567727\n",
      "394 : 2523.729853\n",
      "395 : 2417.61072434\n",
      "396 : 2290.60352295\n",
      "397 : 2341.12695769\n",
      "398 : 2406.82462342\n",
      "399 : 2280.6928013\n",
      "400 : 2330.38611348\n",
      "401 : 2439.98387192\n",
      "402 : 2412.00902306\n",
      "403 : 2340.03237383\n",
      "404 : 2330.24794102\n",
      "405 : 2264.83564737\n",
      "406 : 2292.85930644\n",
      "407 : 2264.70539957\n",
      "408 : 2282.45511919\n",
      "409 : 2217.61485974\n",
      "410 : 2234.87246685\n",
      "411 : 2399.8949849\n",
      "412 : 2348.36700208\n",
      "413 : 2283.06970208\n",
      "414 : 2321.62845456\n",
      "415 : 2411.86569254\n",
      "416 : 2437.67782229\n",
      "417 : 2378.28890572\n",
      "418 : 2430.01576209\n",
      "419 : 2415.08383335\n",
      "420 : 2409.26923874\n",
      "421 : 2355.68132541\n",
      "422 : 2389.12879446\n",
      "423 : 2407.43473676\n",
      "424 : 2398.97883723\n",
      "425 : 2382.04240152\n",
      "426 : 2385.50414214\n",
      "427 : 2314.24756923\n",
      "428 : 2324.03577753\n",
      "429 : 2322.02434282\n",
      "430 : 2286.38849961\n",
      "431 : 2406.91975819\n",
      "432 : 2360.91390438\n",
      "433 : 2300.90817949\n",
      "434 : 2273.89433597\n",
      "435 : 2219.82262849\n",
      "436 : 2205.60646387\n",
      "437 : 2276.93403058\n",
      "438 : 2184.71342665\n",
      "439 : 2256.00865893\n",
      "440 : 2407.02207774\n",
      "441 : 2354.26527919\n",
      "442 : 2383.55496794\n",
      "443 : 2348.0320227\n",
      "444 : 2281.97909577\n",
      "445 : 2266.73954225\n",
      "446 : 2296.1240452\n",
      "447 : 2337.36342581\n",
      "448 : 2354.22418666\n",
      "449 : 2474.306775\n",
      "450 : 2356.40928318\n",
      "451 : 2347.68470399\n",
      "452 : 2285.06634383\n",
      "453 : 2229.742054\n",
      "454 : 2205.6643327\n",
      "455 : 2163.12304062\n",
      "456 : 2280.83744165\n",
      "457 : 2405.30750327\n",
      "458 : 2435.09175586\n",
      "459 : 2316.10877957\n",
      "460 : 2300.52807646\n",
      "461 : 2357.19770589\n",
      "462 : 2544.56254439\n",
      "463 : 2171.45235883\n",
      "464 : 2219.1589741\n",
      "465 : 2173.06586543\n",
      "466 : 2105.82847914\n",
      "467 : 2169.81285376\n",
      "468 : 2153.13933598\n",
      "469 : 2135.22238163\n",
      "470 : 2159.9067526\n",
      "471 : 2165.07917106\n",
      "472 : 2102.41140456\n",
      "473 : 2218.61644185\n",
      "474 : 2099.60524715\n",
      "475 : 2113.89334928\n",
      "476 : 2154.39511598\n",
      "477 : 2111.05123539\n",
      "478 : 2168.39165932\n",
      "479 : 2227.62893003\n",
      "480 : 2180.39917126\n",
      "481 : 2223.98831356\n",
      "482 : 2096.80873872\n",
      "483 : 2032.48315189\n",
      "484 : 2172.32603777\n",
      "485 : 2216.80057032\n",
      "486 : 2149.09815339\n",
      "487 : 2306.78818888\n",
      "488 : 2285.45988502\n",
      "489 : 2222.92556946\n",
      "490 : 2221.59050215\n",
      "491 : 2255.45004158\n",
      "492 : 2289.74563551\n",
      "493 : 2174.40469727\n",
      "494 : 2204.17021597\n",
      "495 : 2240.68261545\n",
      "496 : 2257.25138798\n",
      "497 : 2329.09011081\n",
      "498 : 2243.9799766\n",
      "499 : 2312.39304546\n"
     ]
    }
   ],
   "source": [
    "V_temp = V0\n",
    "W_temp = W0\n",
    "ind = nr.choice(50000,50000, replace = False)\n",
    "loss = []\n",
    "for j in range(500):\n",
    "    V_temp, W_temp = train_cross_entropy(V_temp, W_temp, tr_img, tr_lb, ind, j, j+1, 0.01)\n",
    "    loss_temp = calculate_loss(V_temp, W_temp, tr_img, tr_lb, mean_squared)\n",
    "    print(j, ':', loss_temp)\n",
    "    loss = np.append(loss, [loss_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V1, W1 = (V_temp, W_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 2131.68361506\n",
      "1 : 2239.21629527\n",
      "2 : 2141.299011\n",
      "3 : 2177.4032656\n",
      "4 : 2152.71774686\n",
      "5 : 2100.13056585\n",
      "6 : 2063.03047832\n",
      "7 : 2253.72983597\n",
      "8 : 2188.0815015\n",
      "9 : 2048.68205625\n",
      "10 : 2059.82275364\n",
      "11 : 2103.55324848\n",
      "12 : 2012.03336882\n",
      "13 : 2031.89138515\n",
      "14 : 1992.99635758\n",
      "15 : 2003.66943677\n",
      "16 : 2005.01650948\n",
      "17 : 2009.89931144\n",
      "18 : 1964.8693643\n",
      "19 : 1976.66856727\n",
      "20 : 2074.75036626\n",
      "21 : 1915.95177943\n",
      "22 : 1971.68624854\n",
      "23 : 1970.4870967\n",
      "24 : 2038.05327975\n",
      "25 : 2007.79276962\n",
      "26 : 2199.57572599\n",
      "27 : 2074.23039717\n",
      "28 : 2049.20359072\n",
      "29 : 2016.2180123\n",
      "30 : 2072.76581039\n",
      "31 : 1932.08817488\n",
      "32 : 1979.11928953\n",
      "33 : 1917.05262618\n",
      "34 : 1908.67575909\n",
      "35 : 1950.33675721\n",
      "36 : 1957.7083667\n",
      "37 : 2006.44775612\n",
      "38 : 1946.06352159\n",
      "39 : 1941.3885433\n",
      "40 : 1923.21175838\n",
      "41 : 1920.18745028\n",
      "42 : 1940.25837992\n",
      "43 : 1951.5320429\n",
      "44 : 1913.00647776\n",
      "45 : 1880.84979774\n",
      "46 : 1876.53148798\n",
      "47 : 1907.69355618\n",
      "48 : 1900.46772235\n",
      "49 : 1889.07203212\n",
      "50 : 1852.29777431\n",
      "51 : 1932.60097347\n",
      "52 : 1890.64119051\n",
      "53 : 1907.76302325\n",
      "54 : 1938.85044106\n",
      "55 : 1987.54634818\n",
      "56 : 1974.31858348\n",
      "57 : 1975.42531881\n",
      "58 : 1960.08288811\n",
      "59 : 1906.36537058\n",
      "60 : 2012.32178069\n",
      "61 : 2024.19063745\n",
      "62 : 1912.04286234\n",
      "63 : 1887.7578457\n",
      "64 : 1963.97641751\n",
      "65 : 2017.04490448\n",
      "66 : 1871.32297327\n",
      "67 : 1948.22333455\n",
      "68 : 1994.6878699\n",
      "69 : 1982.03224498\n",
      "70 : 1888.53732818\n",
      "71 : 1897.63080501\n",
      "72 : 1903.98856997\n",
      "73 : 1904.45768671\n",
      "74 : 1961.43944912\n",
      "75 : 1910.69763125\n",
      "76 : 1962.56410296\n",
      "77 : 2002.72747824\n",
      "78 : 1882.45281375\n",
      "79 : 1941.8926077\n",
      "80 : 1964.68518504\n",
      "81 : 1979.14751961\n",
      "82 : 1982.27851564\n",
      "83 : 1821.17919629\n",
      "84 : 1815.6058177\n",
      "85 : 1780.94607215\n",
      "86 : 1822.05126262\n",
      "87 : 1829.94935947\n",
      "88 : 1878.77171499\n",
      "89 : 1801.11866413\n",
      "90 : 1867.52130186\n",
      "91 : 1799.93508861\n",
      "92 : 1893.83171727\n",
      "93 : 1844.81465418\n",
      "94 : 1811.25547752\n",
      "95 : 1757.11787139\n",
      "96 : 1772.35167008\n",
      "97 : 1732.23360904\n",
      "98 : 1732.5529145\n",
      "99 : 1799.70107428\n",
      "100 : 1784.1862964\n",
      "101 : 1862.67715186\n",
      "102 : 1902.20591671\n",
      "103 : 1856.57878683\n",
      "104 : 1822.76126587\n",
      "105 : 1837.8774155\n",
      "106 : 1798.6137676\n",
      "107 : 1790.56372205\n",
      "108 : 1865.50114743\n",
      "109 : 1855.31030509\n",
      "110 : 1833.95163912\n",
      "111 : 1871.73612967\n",
      "112 : 1888.34946172\n",
      "113 : 1868.35133255\n",
      "114 : 1844.41907549\n",
      "115 : 1847.23059193\n",
      "116 : 1914.32404759\n",
      "117 : 1852.44640318\n",
      "118 : 1812.82508274\n",
      "119 : 1807.1081255\n",
      "120 : 1839.44321528\n",
      "121 : 1792.11531147\n",
      "122 : 1889.48007228\n",
      "123 : 1791.1520447\n",
      "124 : 1792.18313777\n",
      "125 : 1770.81149565\n",
      "126 : 1789.48093406\n",
      "127 : 1757.7962185\n",
      "128 : 1781.44902297\n",
      "129 : 1823.40492049\n",
      "130 : 1810.20122646\n",
      "131 : 1823.73774567\n",
      "132 : 1840.75016331\n",
      "133 : 1861.01073144\n",
      "134 : 1885.36250902\n",
      "135 : 1829.34630674\n",
      "136 : 1800.84431589\n",
      "137 : 1787.39873876\n",
      "138 : 1766.30669432\n",
      "139 : 1821.83993996\n",
      "140 : 1994.59501528\n",
      "141 : 1790.70829732\n",
      "142 : 1792.81637329\n",
      "143 : 1735.91716928\n",
      "144 : 1723.79005939\n",
      "145 : 1712.17431403\n",
      "146 : 1718.76620276\n",
      "147 : 1896.62560173\n",
      "148 : 1796.55426733\n",
      "149 : 1793.381105\n",
      "150 : 1792.76634482\n",
      "151 : 1779.87222435\n",
      "152 : 1769.69564532\n",
      "153 : 1797.16400991\n",
      "154 : 1784.62748087\n",
      "155 : 1751.70365953\n",
      "156 : 1801.93701076\n",
      "157 : 1792.77090787\n",
      "158 : 1753.56603123\n",
      "159 : 1750.46554595\n",
      "160 : 1709.83814066\n",
      "161 : 1727.51598301\n",
      "162 : 1773.50701586\n",
      "163 : 1751.98837433\n",
      "164 : 1747.22003495\n",
      "165 : 1781.75822997\n",
      "166 : 1976.00623823\n",
      "167 : 1805.55118673\n",
      "168 : 1762.27085772\n",
      "169 : 1791.92833856\n",
      "170 : 1695.19688197\n",
      "171 : 1683.90669419\n",
      "172 : 1698.70782634\n",
      "173 : 1691.93581467\n",
      "174 : 1716.42007071\n",
      "175 : 1746.55594484\n",
      "176 : 1841.86010287\n",
      "177 : 1799.31730356\n",
      "178 : 1892.27716386\n",
      "179 : 1926.37868064\n",
      "180 : 1911.6522151\n",
      "181 : 1851.86052451\n",
      "182 : 1855.7292336\n",
      "183 : 1799.77589603\n",
      "184 : 1769.60716119\n",
      "185 : 1768.17108821\n",
      "186 : 1768.75999871\n",
      "187 : 1735.73040757\n",
      "188 : 1737.84716526\n",
      "189 : 1697.17865786\n",
      "190 : 1723.3537723\n",
      "191 : 1732.45988486\n",
      "192 : 1807.6880115\n",
      "193 : 1708.10021659\n",
      "194 : 1709.73811996\n",
      "195 : 1731.34485076\n",
      "196 : 1778.58034405\n",
      "197 : 1803.27134928\n",
      "198 : 1732.48514438\n",
      "199 : 1835.99110971\n",
      "200 : 1758.03026504\n",
      "201 : 1766.08907399\n",
      "202 : 1764.08888638\n",
      "203 : 1692.07876153\n",
      "204 : 1725.12286284\n",
      "205 : 1775.77076554\n",
      "206 : 1672.10991391\n",
      "207 : 1683.52361162\n",
      "208 : 1665.23652216\n",
      "209 : 1668.40489064\n",
      "210 : 1678.88651001\n",
      "211 : 1676.14890228\n",
      "212 : 1680.19153644\n",
      "213 : 1680.99365546\n",
      "214 : 1687.76917815\n",
      "215 : 1716.68423642\n",
      "216 : 1699.00269667\n",
      "217 : 1703.7498202\n",
      "218 : 1647.23086391\n",
      "219 : 1784.5734889\n",
      "220 : 1773.42100072\n",
      "221 : 1698.39414883\n",
      "222 : 1764.15842004\n",
      "223 : 1846.39163812\n",
      "224 : 1765.53893114\n",
      "225 : 1699.25097529\n",
      "226 : 1713.11071943\n",
      "227 : 1724.55441976\n",
      "228 : 1694.48107364\n",
      "229 : 1680.35828508\n",
      "230 : 1677.24704814\n",
      "231 : 1689.50627527\n",
      "232 : 1718.26069186\n",
      "233 : 1751.29301404\n",
      "234 : 1739.9949143\n",
      "235 : 1711.75807265\n",
      "236 : 1756.17704195\n",
      "237 : 1723.56930448\n",
      "238 : 1847.95690583\n",
      "239 : 1826.39018341\n",
      "240 : 1782.13578917\n",
      "241 : 1736.48005325\n",
      "242 : 2040.70583554\n",
      "243 : 1877.60054551\n",
      "244 : 1765.6911877\n",
      "245 : 1700.49945038\n",
      "246 : 1697.64044177\n",
      "247 : 1653.40851724\n",
      "248 : 1682.0183904\n",
      "249 : 1748.50319655\n",
      "250 : 1697.83373549\n",
      "251 : 1774.04799047\n",
      "252 : 1730.04904351\n",
      "253 : 1723.08582295\n",
      "254 : 1704.17661195\n",
      "255 : 1710.04305451\n",
      "256 : 1686.65549074\n",
      "257 : 1642.83809638\n",
      "258 : 1703.52848313\n",
      "259 : 1676.60663909\n",
      "260 : 1660.63968016\n",
      "261 : 1611.31411755\n",
      "262 : 1613.47705381\n",
      "263 : 1642.0598229\n",
      "264 : 1721.82692451\n",
      "265 : 1673.32187806\n",
      "266 : 1742.69637392\n",
      "267 : 1704.25490667\n",
      "268 : 1670.72643677\n",
      "269 : 1737.60943783\n",
      "270 : 1810.81101934\n",
      "271 : 1746.99073174\n",
      "272 : 1779.20712425\n",
      "273 : 1772.06573315\n",
      "274 : 1778.35233995\n",
      "275 : 1732.55465662\n",
      "276 : 1704.05284592\n",
      "277 : 1689.03939549\n",
      "278 : 1753.16434436\n",
      "279 : 1755.46313025\n",
      "280 : 1787.80914568\n",
      "281 : 1732.99910045\n",
      "282 : 1679.74579253\n",
      "283 : 1632.23564168\n",
      "284 : 1646.54387503\n",
      "285 : 1725.09769542\n",
      "286 : 1696.66089867\n",
      "287 : 1665.31061202\n",
      "288 : 1779.20713458\n",
      "289 : 1788.32924201\n",
      "290 : 1839.00032751\n",
      "291 : 1701.02517967\n",
      "292 : 1630.75682419\n",
      "293 : 1650.31247492\n",
      "294 : 1665.07184999\n",
      "295 : 1730.86123773\n",
      "296 : 1712.96689994\n",
      "297 : 1704.59098503\n",
      "298 : 1674.38399835\n",
      "299 : 1657.61969671\n",
      "300 : 1681.8897707\n",
      "301 : 1636.02057697\n",
      "302 : 1633.00938118\n",
      "303 : 1619.10891517\n",
      "304 : 1634.91589945\n",
      "305 : 1590.04838461\n",
      "306 : 1611.06408748\n",
      "307 : 1590.30777679\n",
      "308 : 1676.42795078\n",
      "309 : 1711.65365703\n",
      "310 : 1683.21629572\n",
      "311 : 1646.90496905\n",
      "312 : 1625.60226197\n",
      "313 : 1654.9278434\n",
      "314 : 1773.01073724\n",
      "315 : 1704.14126711\n",
      "316 : 1703.41552974\n",
      "317 : 1679.39617668\n",
      "318 : 1726.80843039\n",
      "319 : 1721.29598492\n",
      "320 : 1715.31307922\n",
      "321 : 1689.40406313\n",
      "322 : 1738.82586227\n",
      "323 : 1755.78473119\n",
      "324 : 1633.3724101\n",
      "325 : 1647.93373294\n",
      "326 : 1716.6822689\n",
      "327 : 1688.15561778\n",
      "328 : 1657.8910312\n",
      "329 : 1679.53153091\n",
      "330 : 1695.93629195\n",
      "331 : 1670.49874009\n",
      "332 : 1643.95408659\n",
      "333 : 1646.55635871\n",
      "334 : 1714.09940307\n",
      "335 : 1731.58169452\n",
      "336 : 1716.66031831\n",
      "337 : 1639.93429076\n",
      "338 : 1611.22622024\n",
      "339 : 1622.84579344\n",
      "340 : 1707.55444209\n",
      "341 : 1665.30712327\n",
      "342 : 1643.47375055\n",
      "343 : 1592.55579822\n",
      "344 : 1615.42367693\n",
      "345 : 1581.78109621\n",
      "346 : 1560.98123057\n",
      "347 : 1602.54144276\n",
      "348 : 1664.90584107\n",
      "349 : 1670.96515108\n",
      "350 : 1624.41020837\n",
      "351 : 1608.77089754\n",
      "352 : 1575.40075852\n",
      "353 : 1607.38102988\n",
      "354 : 1605.88583397\n",
      "355 : 1579.10020609\n",
      "356 : 1567.30840086\n",
      "357 : 1568.32890617\n",
      "358 : 1569.69753462\n",
      "359 : 1621.36670308\n",
      "360 : 1657.02849943\n",
      "361 : 1622.96481689\n",
      "362 : 1748.39306429\n",
      "363 : 1663.0152291\n",
      "364 : 1594.82071637\n",
      "365 : 1593.47173075\n",
      "366 : 1570.30616906\n",
      "367 : 1569.44917891\n",
      "368 : 1582.76410228\n",
      "369 : 1590.09766141\n",
      "370 : 1614.28040937\n",
      "371 : 1561.04888625\n",
      "372 : 1567.14580471\n",
      "373 : 1570.88164723\n",
      "374 : 1566.56369439\n",
      "375 : 1655.49452781\n",
      "376 : 1558.67437396\n",
      "377 : 1584.6805959\n",
      "378 : 1589.21023259\n",
      "379 : 1663.4446732\n",
      "380 : 1609.51799804\n",
      "381 : 1559.28130352\n",
      "382 : 1552.17478689\n",
      "383 : 1624.90223728\n",
      "384 : 1640.36713209\n",
      "385 : 1560.30742975\n",
      "386 : 1563.46504448\n",
      "387 : 1564.38698312\n",
      "388 : 1624.46034046\n",
      "389 : 1554.30164169\n",
      "390 : 1588.72281061\n",
      "391 : 1580.66200805\n",
      "392 : 1538.37478915\n",
      "393 : 1651.54719723\n",
      "394 : 1700.29652861\n",
      "395 : 1662.35991931\n",
      "396 : 1695.83421956\n",
      "397 : 1781.05513251\n",
      "398 : 1651.03196732\n",
      "399 : 1627.45664996\n",
      "400 : 1704.31731396\n",
      "401 : 1645.58318668\n",
      "402 : 1629.66061486\n",
      "403 : 1620.30432618\n",
      "404 : 1633.62559828\n",
      "405 : 1624.63464936\n",
      "406 : 1671.81755293\n",
      "407 : 1723.45639242\n",
      "408 : 1654.77664\n",
      "409 : 1647.22685154\n",
      "410 : 1602.25038596\n",
      "411 : 1706.32436974\n",
      "412 : 1663.37171565\n",
      "413 : 1633.45859505\n",
      "414 : 1676.86692561\n",
      "415 : 1626.537036\n",
      "416 : 1586.35831879\n",
      "417 : 1621.95491013\n",
      "418 : 1571.83497553\n",
      "419 : 1600.07872864\n",
      "420 : 1598.70171845\n",
      "421 : 1639.83219099\n",
      "422 : 1753.10655396\n",
      "423 : 1633.36135515\n",
      "424 : 1613.26548588\n",
      "425 : 1564.26329096\n",
      "426 : 1552.95012544\n",
      "427 : 1589.92279401\n",
      "428 : 1712.18280473\n",
      "429 : 1618.20186899\n",
      "430 : 1605.0155781\n",
      "431 : 1551.32340018\n",
      "432 : 1537.96061426\n",
      "433 : 1519.59788941\n",
      "434 : 1542.1666187\n",
      "435 : 1561.82305545\n",
      "436 : 1520.60275738\n",
      "437 : 1515.50171889\n",
      "438 : 1557.73017592\n",
      "439 : 1525.20533883\n",
      "440 : 1538.63774573\n",
      "441 : 1524.58761124\n",
      "442 : 1500.02064426\n",
      "443 : 1529.04930818\n",
      "444 : 1484.8704173\n",
      "445 : 1499.53347755\n",
      "446 : 1519.15858584\n",
      "447 : 1520.18738989\n",
      "448 : 1486.04996842\n",
      "449 : 1480.59951401\n",
      "450 : 1456.01632878\n",
      "451 : 1476.59655432\n",
      "452 : 1553.87537233\n",
      "453 : 1643.45285819\n",
      "454 : 1536.42361833\n",
      "455 : 1495.99130638\n",
      "456 : 1475.7731047\n",
      "457 : 1440.89557816\n",
      "458 : 1484.98009543\n",
      "459 : 1493.07646101\n",
      "460 : 1483.96195662\n",
      "461 : 1492.70922879\n",
      "462 : 1521.25295063\n",
      "463 : 1533.19264175\n",
      "464 : 1492.32862593\n",
      "465 : 1478.7515109\n",
      "466 : 1467.74783105\n",
      "467 : 1515.51955482\n",
      "468 : 1515.0436334\n",
      "469 : 1521.45609275\n",
      "470 : 1495.74690894\n",
      "471 : 1465.45211166\n",
      "472 : 1545.00508259\n",
      "473 : 1567.16399913\n",
      "474 : 1580.74594928\n",
      "475 : 1542.11653083\n",
      "476 : 1622.49911775\n",
      "477 : 1573.37395733\n",
      "478 : 1527.90615988\n",
      "479 : 1584.81709597\n",
      "480 : 1496.35388129\n",
      "481 : 1548.24764458\n",
      "482 : 1527.38570324\n",
      "483 : 1477.23079085\n",
      "484 : 1473.79945967\n",
      "485 : 1541.39211274\n",
      "486 : 1574.37023033\n",
      "487 : 1485.86598395\n",
      "488 : 1566.85500231\n",
      "489 : 1538.87885991\n",
      "490 : 1593.5766943\n",
      "491 : 1514.79420342\n",
      "492 : 1565.11447109\n",
      "493 : 1533.86622543\n",
      "494 : 1548.02824547\n",
      "495 : 1520.08581728\n",
      "496 : 1528.03914255\n",
      "497 : 1516.56387665\n",
      "498 : 1506.74982404\n",
      "499 : 1532.28973833\n"
     ]
    }
   ],
   "source": [
    "V_temp = V1\n",
    "W_temp = W1\n",
    "ind = nr.choice(50000,50000, replace = False)\n",
    "loss = []\n",
    "for j in range(500):\n",
    "    V_temp, W_temp = train_cross_entropy(V_temp, W_temp, tr_img, tr_lb, ind, j, j+1, 0.01)\n",
    "    loss_temp = calculate_loss(V_temp, W_temp, tr_img, tr_lb, mean_squared)\n",
    "    print(j, ':', loss_temp)\n",
    "    loss = np.append(loss, [loss_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V2, W2, loss2 = (V_temp, W_temp, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1518.88366495\n",
      "1 : 1472.68700892\n",
      "2 : 1437.62181461\n",
      "3 : 1396.72880676\n",
      "4 : 1418.97733638\n",
      "5 : 1403.41458587\n",
      "6 : 1405.3019995\n",
      "7 : 1379.97832374\n",
      "8 : 1369.87057909\n",
      "9 : 1364.61401999\n",
      "10 : 1352.1224759\n",
      "11 : 1337.61787427\n",
      "12 : 1323.62192572\n",
      "13 : 1309.8646066\n",
      "14 : 1298.29256177\n",
      "15 : 1285.48817468\n",
      "16 : 1267.91751903\n",
      "17 : 1256.70808696\n",
      "18 : 1260.08949812\n",
      "19 : 1258.83277902\n",
      "20 : 1268.96367254\n",
      "21 : 1260.127289\n",
      "22 : 1253.42083281\n",
      "23 : 1228.40892467\n",
      "24 : 1233.0390875\n",
      "25 : 1207.16206421\n",
      "26 : 1219.32495575\n",
      "27 : 1219.69926901\n",
      "28 : 1222.72249881\n",
      "29 : 1198.74396724\n",
      "30 : 1190.84161247\n",
      "31 : 1182.38808732\n",
      "32 : 1191.57893976\n",
      "33 : 1171.96580938\n",
      "34 : 1171.88984645\n",
      "35 : 1164.22692815\n",
      "36 : 1169.23692589\n",
      "37 : 1164.98306185\n",
      "38 : 1167.87644755\n",
      "39 : 1160.28113862\n",
      "40 : 1168.27694946\n",
      "41 : 1171.62881617\n",
      "42 : 1177.5952027\n",
      "43 : 1152.30978045\n",
      "44 : 1153.20228718\n",
      "45 : 1150.16257075\n",
      "46 : 1145.03274988\n",
      "47 : 1146.14037235\n",
      "48 : 1145.99205295\n",
      "49 : 1157.94312826\n",
      "50 : 1158.65137601\n",
      "51 : 1163.33586918\n",
      "52 : 1162.04148241\n",
      "53 : 1143.07210196\n",
      "54 : 1132.54290275\n",
      "55 : 1123.84717472\n",
      "56 : 1119.94156333\n",
      "57 : 1114.84742636\n",
      "58 : 1111.72305543\n",
      "59 : 1113.89934325\n",
      "60 : 1122.58787348\n",
      "61 : 1108.05060448\n",
      "62 : 1092.40288514\n",
      "63 : 1087.66908386\n",
      "64 : 1084.81893337\n",
      "65 : 1080.04728134\n",
      "66 : 1070.78356811\n",
      "67 : 1074.13294053\n",
      "68 : 1076.32919893\n",
      "69 : 1078.60284621\n",
      "70 : 1070.96586737\n",
      "71 : 1065.16672622\n",
      "72 : 1048.00940701\n",
      "73 : 1068.65067115\n",
      "74 : 1093.41910465\n",
      "75 : 1082.84948228\n",
      "76 : 1074.30329606\n",
      "77 : 1067.02490553\n",
      "78 : 1047.75238556\n",
      "79 : 1048.57310937\n",
      "80 : 1055.08324199\n",
      "81 : 1054.95791728\n",
      "82 : 1059.79117665\n",
      "83 : 1051.38875145\n",
      "84 : 1048.52100442\n",
      "85 : 1037.35423198\n",
      "86 : 1041.75346303\n",
      "87 : 1063.85746828\n",
      "88 : 1047.2304816\n",
      "89 : 1055.99360544\n",
      "90 : 1057.1755441\n",
      "91 : 1041.28356482\n",
      "92 : 1030.66740775\n",
      "93 : 1039.51286148\n",
      "94 : 1032.35484419\n",
      "95 : 1029.17316538\n",
      "96 : 1025.39927143\n",
      "97 : 1025.56083379\n",
      "98 : 1017.88450108\n",
      "99 : 1013.80164612\n",
      "100 : 998.334788263\n",
      "101 : 990.54390504\n",
      "102 : 999.064495244\n",
      "103 : 990.639625189\n",
      "104 : 986.154912006\n",
      "105 : 1000.0669134\n",
      "106 : 1006.70100587\n",
      "107 : 997.170961547\n",
      "108 : 989.854062484\n",
      "109 : 988.615586446\n",
      "110 : 978.479263173\n",
      "111 : 979.770971059\n",
      "112 : 987.678044903\n",
      "113 : 983.483297339\n",
      "114 : 979.508568515\n",
      "115 : 981.95675563\n",
      "116 : 983.543114609\n",
      "117 : 968.162078049\n",
      "118 : 973.337954526\n",
      "119 : 974.457063198\n",
      "120 : 968.427779516\n",
      "121 : 969.629558488\n",
      "122 : 962.898352185\n",
      "123 : 965.274206012\n",
      "124 : 984.822719824\n",
      "125 : 977.923140531\n",
      "126 : 985.495386497\n",
      "127 : 984.48751926\n",
      "128 : 967.188410413\n",
      "129 : 966.013678156\n",
      "130 : 972.387695529\n",
      "131 : 971.587178614\n",
      "132 : 957.369960689\n",
      "133 : 964.072344411\n",
      "134 : 962.078347365\n",
      "135 : 969.680097133\n",
      "136 : 986.288551099\n",
      "137 : 977.812909045\n",
      "138 : 963.725043794\n",
      "139 : 964.445166757\n",
      "140 : 951.680231639\n",
      "141 : 951.745257336\n",
      "142 : 959.454262559\n",
      "143 : 962.501490689\n",
      "144 : 957.492094269\n",
      "145 : 950.160930192\n",
      "146 : 938.792542542\n",
      "147 : 946.246307874\n",
      "148 : 955.263755116\n",
      "149 : 956.811730124\n",
      "150 : 960.051494519\n",
      "151 : 947.651332339\n",
      "152 : 945.793449798\n",
      "153 : 946.228092237\n",
      "154 : 935.519692122\n",
      "155 : 924.385110789\n",
      "156 : 920.211703879\n",
      "157 : 916.917290256\n",
      "158 : 920.854846857\n",
      "159 : 929.15911283\n",
      "160 : 926.600548198\n",
      "161 : 951.415193078\n",
      "162 : 928.481245182\n",
      "163 : 929.851179979\n",
      "164 : 929.967196548\n",
      "165 : 919.59668469\n",
      "166 : 906.715670326\n",
      "167 : 903.835298149\n",
      "168 : 894.113106687\n",
      "169 : 892.75720251\n",
      "170 : 895.614968172\n",
      "171 : 899.605476013\n",
      "172 : 890.999539267\n",
      "173 : 886.939636716\n",
      "174 : 886.855564289\n",
      "175 : 885.049186409\n",
      "176 : 905.220653514\n",
      "177 : 897.677288304\n",
      "178 : 891.747224963\n",
      "179 : 889.144435201\n",
      "180 : 887.31618603\n",
      "181 : 887.096649401\n",
      "182 : 875.283651177\n",
      "183 : 869.398876164\n",
      "184 : 873.167270086\n",
      "185 : 867.728730336\n",
      "186 : 864.522690722\n",
      "187 : 875.134160572\n",
      "188 : 874.927151313\n",
      "189 : 886.592308548\n",
      "190 : 877.84950261\n",
      "191 : 877.625599515\n",
      "192 : 872.39204966\n",
      "193 : 865.875249248\n",
      "194 : 859.508806402\n",
      "195 : 864.85106546\n",
      "196 : 879.641571673\n",
      "197 : 869.241451982\n",
      "198 : 885.026523976\n",
      "199 : 884.749882896\n",
      "200 : 880.12502323\n",
      "201 : 883.342532967\n",
      "202 : 880.600481826\n",
      "203 : 869.665061851\n",
      "204 : 878.3910257\n",
      "205 : 858.754190442\n",
      "206 : 867.464882123\n",
      "207 : 860.568149823\n",
      "208 : 846.880269343\n",
      "209 : 853.572110437\n",
      "210 : 856.640268918\n",
      "211 : 851.833825828\n",
      "212 : 843.652873826\n",
      "213 : 842.124761709\n",
      "214 : 860.246480736\n",
      "215 : 855.492842549\n",
      "216 : 847.444543823\n",
      "217 : 831.914933927\n",
      "218 : 827.914115529\n",
      "219 : 824.339742998\n",
      "220 : 825.170673858\n",
      "221 : 820.225480454\n",
      "222 : 817.101123617\n",
      "223 : 830.083855173\n",
      "224 : 825.563405994\n",
      "225 : 816.164266474\n",
      "226 : 820.539937784\n",
      "227 : 815.416464411\n",
      "228 : 816.433403468\n",
      "229 : 810.354977539\n",
      "230 : 811.389949906\n",
      "231 : 809.843698203\n",
      "232 : 811.902348515\n",
      "233 : 806.606840134\n",
      "234 : 811.843284725\n",
      "235 : 816.370238611\n",
      "236 : 818.976584898\n",
      "237 : 813.868414548\n",
      "238 : 823.103583048\n",
      "239 : 816.876844249\n",
      "240 : 820.863341128\n",
      "241 : 817.188216742\n",
      "242 : 800.472648266\n",
      "243 : 815.412013257\n",
      "244 : 815.84710348\n",
      "245 : 819.131369186\n",
      "246 : 802.607507232\n",
      "247 : 792.822447915\n",
      "248 : 788.835929914\n",
      "249 : 788.036791592\n",
      "250 : 776.406842595\n",
      "251 : 785.847781134\n",
      "252 : 792.826666101\n",
      "253 : 788.512195019\n",
      "254 : 786.525538137\n",
      "255 : 789.697813371\n",
      "256 : 782.357123926\n",
      "257 : 787.958118587\n",
      "258 : 778.933213098\n",
      "259 : 778.299676642\n",
      "260 : 777.091913487\n",
      "261 : 771.552669515\n",
      "262 : 771.397102095\n",
      "263 : 779.878457057\n",
      "264 : 790.929872696\n",
      "265 : 794.473030059\n",
      "266 : 777.704167916\n",
      "267 : 771.270175429\n",
      "268 : 768.67972655\n",
      "269 : 768.980912515\n",
      "270 : 785.527983509\n",
      "271 : 767.280375188\n",
      "272 : 766.406777643\n",
      "273 : 765.877240766\n",
      "274 : 781.068994214\n",
      "275 : 794.831720454\n",
      "276 : 795.2915012\n",
      "277 : 798.067301287\n",
      "278 : 787.670515899\n",
      "279 : 795.391653792\n",
      "280 : 788.438854913\n",
      "281 : 767.111933577\n",
      "282 : 762.251669749\n",
      "283 : 759.60254462\n",
      "284 : 760.158269576\n",
      "285 : 764.133857233\n",
      "286 : 760.598059782\n",
      "287 : 758.284821573\n",
      "288 : 757.795638538\n",
      "289 : 767.887319182\n",
      "290 : 766.5221172\n",
      "291 : 780.612485799\n",
      "292 : 769.822265683\n",
      "293 : 772.461675738\n",
      "294 : 767.250476497\n",
      "295 : 758.406338797\n",
      "296 : 759.988717421\n",
      "297 : 769.253815179\n",
      "298 : 749.790365965\n",
      "299 : 744.131713975\n",
      "300 : 742.07073589\n",
      "301 : 744.463129354\n",
      "302 : 741.290670663\n",
      "303 : 745.974800604\n",
      "304 : 739.630044829\n",
      "305 : 761.736494697\n",
      "306 : 758.186411582\n",
      "307 : 748.721308409\n",
      "308 : 740.794175066\n",
      "309 : 732.501853075\n",
      "310 : 739.010440821\n",
      "311 : 732.428829491\n",
      "312 : 736.440998736\n",
      "313 : 725.761262679\n",
      "314 : 727.784353533\n",
      "315 : 753.912159585\n",
      "316 : 747.493285848\n",
      "317 : 747.090833791\n",
      "318 : 732.760898881\n",
      "319 : 720.080316688\n",
      "320 : 733.772987265\n",
      "321 : 729.566393828\n",
      "322 : 753.514262661\n",
      "323 : 733.35641678\n",
      "324 : 738.146768977\n",
      "325 : 729.801950848\n",
      "326 : 737.580912662\n",
      "327 : 737.144008515\n",
      "328 : 715.734742711\n",
      "329 : 714.976773448\n",
      "330 : 715.247023348\n",
      "331 : 719.941247735\n",
      "332 : 721.594022163\n",
      "333 : 719.703493184\n",
      "334 : 738.179138818\n",
      "335 : 738.68706739\n",
      "336 : 727.55602687\n",
      "337 : 721.007700309\n",
      "338 : 703.056988922\n",
      "339 : 704.946061958\n",
      "340 : 714.664844224\n",
      "341 : 708.695728364\n",
      "342 : 707.647343443\n",
      "343 : 711.088668908\n",
      "344 : 706.248559221\n",
      "345 : 705.180938548\n",
      "346 : 699.028980815\n",
      "347 : 699.994413305\n",
      "348 : 717.759189964\n",
      "349 : 712.033175799\n",
      "350 : 711.420854009\n",
      "351 : 715.171803351\n",
      "352 : 706.85686542\n",
      "353 : 709.322230557\n",
      "354 : 718.199009406\n",
      "355 : 706.999438502\n",
      "356 : 705.586826369\n",
      "357 : 696.526376745\n",
      "358 : 703.223785333\n",
      "359 : 721.415497522\n",
      "360 : 708.44900025\n",
      "361 : 700.964857211\n",
      "362 : 699.58146457\n",
      "363 : 707.641902819\n",
      "364 : 692.107589596\n",
      "365 : 691.565306358\n",
      "366 : 683.446944616\n",
      "367 : 685.525598906\n",
      "368 : 686.108536513\n",
      "369 : 685.09883715\n",
      "370 : 670.523030087\n",
      "371 : 695.693789242\n",
      "372 : 688.164877969\n",
      "373 : 687.559507067\n",
      "374 : 679.060463548\n",
      "375 : 673.724131415\n",
      "376 : 680.718139963\n",
      "377 : 686.387854001\n",
      "378 : 688.155831311\n",
      "379 : 687.502259787\n",
      "380 : 681.298878699\n",
      "381 : 687.391103662\n",
      "382 : 688.64500226\n",
      "383 : 695.386627361\n",
      "384 : 693.687054436\n",
      "385 : 682.413754101\n",
      "386 : 702.17121425\n",
      "387 : 697.299128448\n",
      "388 : 696.001034386\n",
      "389 : 690.771351672\n",
      "390 : 691.304912945\n",
      "391 : 694.415919127\n",
      "392 : 688.566401738\n",
      "393 : 686.51808127\n",
      "394 : 667.007150151\n",
      "395 : 662.961581775\n",
      "396 : 656.907676227\n",
      "397 : 671.620340559\n",
      "398 : 664.961205988\n",
      "399 : 666.546047282\n",
      "400 : 676.746410623\n",
      "401 : 691.580102994\n",
      "402 : 698.143938629\n",
      "403 : 701.256530526\n",
      "404 : 703.005706009\n",
      "405 : 709.617209131\n",
      "406 : 691.908023565\n",
      "407 : 685.7988223\n",
      "408 : 677.520736275\n",
      "409 : 679.807001978\n",
      "410 : 669.366773379\n",
      "411 : 662.843185833\n",
      "412 : 662.627770834\n",
      "413 : 651.511605348\n",
      "414 : 661.645793872\n",
      "415 : 665.318540139\n",
      "416 : 665.557345733\n",
      "417 : 656.022410436\n",
      "418 : 653.248115388\n",
      "419 : 653.101637023\n",
      "420 : 648.088953097\n",
      "421 : 653.486426354\n",
      "422 : 648.485809098\n",
      "423 : 644.354501908\n",
      "424 : 656.022309426\n",
      "425 : 657.309721554\n",
      "426 : 655.889309348\n",
      "427 : 681.502388041\n",
      "428 : 674.879688565\n",
      "429 : 661.725194366\n",
      "430 : 660.627734458\n",
      "431 : 656.073021066\n",
      "432 : 651.391349267\n",
      "433 : 644.784721967\n",
      "434 : 665.549442904\n",
      "435 : 670.284534252\n",
      "436 : 657.591496181\n",
      "437 : 635.166030749\n",
      "438 : 651.027925228\n",
      "439 : 653.995297204\n",
      "440 : 647.609679968\n",
      "441 : 658.04514713\n",
      "442 : 664.317143272\n",
      "443 : 657.374470745\n",
      "444 : 654.406285285\n",
      "445 : 641.07515849\n",
      "446 : 639.656885142\n",
      "447 : 648.874076041\n",
      "448 : 663.790175731\n",
      "449 : 658.218904462\n",
      "450 : 643.961116304\n",
      "451 : 631.049332901\n",
      "452 : 632.058486713\n",
      "453 : 631.64522128\n",
      "454 : 626.226462547\n",
      "455 : 629.23043508\n",
      "456 : 614.091473724\n",
      "457 : 615.704811974\n",
      "458 : 632.323581252\n",
      "459 : 633.462372595\n",
      "460 : 653.42956709\n",
      "461 : 628.868055082\n",
      "462 : 619.901726802\n",
      "463 : 624.917829352\n",
      "464 : 628.806056699\n",
      "465 : 626.098732235\n",
      "466 : 641.07220433\n",
      "467 : 625.69686443\n",
      "468 : 617.877778427\n",
      "469 : 621.346725766\n",
      "470 : 621.024713294\n",
      "471 : 621.144571859\n",
      "472 : 616.019028173\n",
      "473 : 620.977116156\n",
      "474 : 617.718195882\n",
      "475 : 619.879941324\n",
      "476 : 617.115351136\n",
      "477 : 602.162791899\n",
      "478 : 593.918741372\n",
      "479 : 599.898831834\n",
      "480 : 587.564116962\n",
      "481 : 585.901076385\n",
      "482 : 594.96254894\n",
      "483 : 604.345875458\n",
      "484 : 591.815934673\n",
      "485 : 588.783877718\n",
      "486 : 568.409422569\n",
      "487 : 572.884806464\n",
      "488 : 568.797894684\n",
      "489 : 567.979685779\n",
      "490 : 587.342638554\n",
      "491 : 572.014513018\n",
      "492 : 566.261774385\n",
      "493 : 573.28350934\n",
      "494 : 566.397436516\n",
      "495 : 569.49988424\n",
      "496 : 581.44858856\n",
      "497 : 591.424939438\n",
      "498 : 597.372966021\n",
      "499 : 593.135620789\n"
     ]
    }
   ],
   "source": [
    "V_temp = V2\n",
    "W_temp = W2\n",
    "ind = nr.choice(50000,50000, replace = False)\n",
    "loss = []\n",
    "misclass = []\n",
    "for j in range(50):\n",
    "    V_temp, W_temp = train_cross_entropy(V_temp, W_temp, tr_img, tr_lb, ind, j, j+1, 0.01 * 0.5)\n",
    "    loss_temp = calculate_loss(V_temp, W_temp, tr_img, tr_lb, cross_entropy)\n",
    "    mis_temp = misclassification(V_temp, W_temp, tr_img, tr_lb_num)\n",
    "    loss = np.append(loss, [loss_temp])\n",
    "    misclass= np.append(misclass, [mis_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V3,W3,loss3 = (V_temp, W_temp, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 5021.19535318\n",
      "1 : 4980.72587399\n",
      "2 : 4970.43386972\n",
      "3 : 4857.45571119\n",
      "4 : 4896.27282937\n",
      "5 : 4758.05864799\n",
      "6 : 4839.07473864\n",
      "7 : 4770.54219401\n",
      "8 : 4720.96510383\n",
      "9 : 4646.98320973\n",
      "10 : 4619.18157203\n",
      "11 : 4511.70544555\n",
      "12 : 4494.51193733\n",
      "13 : 4523.11011052\n",
      "14 : 4476.570145\n",
      "15 : 4487.95756542\n",
      "16 : 4380.70085515\n",
      "17 : 4318.76090504\n",
      "18 : 4307.79725722\n",
      "19 : 4366.01351285\n",
      "20 : 4407.52082625\n",
      "21 : 4272.09620929\n",
      "22 : 4302.37946203\n",
      "23 : 4228.52307568\n",
      "24 : 4164.58804082\n",
      "25 : 4196.0933082\n",
      "26 : 4108.82706138\n",
      "27 : 4181.22344488\n",
      "28 : 4182.60917499\n",
      "29 : 4082.41160142\n",
      "30 : 4046.94064275\n",
      "31 : 3909.12759841\n",
      "32 : 3959.03055928\n",
      "33 : 3907.34792905\n",
      "34 : 3878.75225026\n",
      "35 : 3946.57584942\n",
      "36 : 3864.55177489\n",
      "37 : 3883.09013801\n",
      "38 : 3701.39023797\n",
      "39 : 3758.25986081\n",
      "40 : 3672.58077769\n",
      "41 : 3754.00353455\n",
      "42 : 3650.54539314\n",
      "43 : 3555.73643215\n",
      "44 : 3783.81261304\n",
      "45 : 3682.44356532\n",
      "46 : 3632.00961739\n",
      "47 : 3588.47317888\n",
      "48 : 3444.64211925\n",
      "49 : 3391.59361413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HYESHOOM/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:16: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "V_temp = V3\n",
    "W_temp = W3\n",
    "ind = nr.choice(50000,50000, replace = False)\n",
    "loss = []\n",
    "misclass = []\n",
    "for j in range(50):\n",
    "    V_temp, W_temp = train_cross_entropy(V_temp, W_temp, tr_img, tr_lb, ind, j, j+1, 0.01 * 0.5)\n",
    "    loss_temp = calculate_loss(V_temp, W_temp, tr_img, tr_lb, cross_entropy)\n",
    "    mis_temp = misclassification(V_temp, W_temp, tr_img, tr_lb_num)\n",
    "    print(j, ':', loss_temp)\n",
    "    loss = np.append(loss, [loss_temp])\n",
    "    misclass= np.append(misclass, [mis_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V4,W4,loss4 = (V_temp, W_temp, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predict(V_temp, W_temp, tr_img), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 3276.54200273 0.00416\n",
      "1 : 3227.76496375 0.0041\n",
      "2 : 3178.67085123 0.00404\n",
      "3 : 3170.57205328 0.00398\n",
      "4 : 3118.23086945 0.0037\n",
      "5 : 3077.22647014 0.00378\n",
      "6 : 3036.80179254 0.00366\n",
      "7 : 3027.12613261 0.00356\n",
      "8 : 2989.76033637 0.00338\n",
      "9 : 2977.84970447 0.00352\n",
      "10 : 2940.90096923 0.00346\n",
      "11 : 2945.26391913 0.00352\n",
      "12 : 2909.25873887 0.00336\n",
      "13 : 2880.5142112 0.00338\n",
      "14 : 2842.7032195 0.00318\n",
      "15 : 2831.89945389 0.00322\n",
      "16 : 2781.31628191 0.00316\n",
      "17 : 2766.95286153 0.00316\n",
      "18 : 2750.95468067 0.00304\n",
      "19 : 2744.42380028 0.00298\n",
      "20 : 2743.00301528 0.0031\n",
      "21 : 2726.80107928 0.00302\n",
      "22 : 2685.992867 0.00298\n",
      "23 : 2688.20781961 0.00302\n",
      "24 : 2660.11207628 0.00302\n",
      "25 : 2662.87670895 0.00306\n",
      "26 : 2632.49497007 0.003\n",
      "27 : 2661.41898186 0.00298\n",
      "28 : 2624.70503203 0.00288\n",
      "29 : 2645.93257955 0.00284\n",
      "30 : 2606.00665401 0.00278\n",
      "31 : 2589.87675422 0.00288\n",
      "32 : 2540.8363283 0.00278\n",
      "33 : 2538.50845851 0.00274\n",
      "34 : 2543.13273226 0.00274\n",
      "35 : 2522.51816174 0.00256\n",
      "36 : 2478.04218555 0.00246\n",
      "37 : 2455.75245958 0.00238\n",
      "38 : 2439.68942699 0.0024\n",
      "39 : 2418.51690018 0.00248\n",
      "40 : 2421.29498952 0.00258\n",
      "41 : 2393.67834918 0.00244\n",
      "42 : 2385.02830925 0.00236\n",
      "43 : 2387.65133063 0.00226\n",
      "44 : 2359.17222342 0.00224\n",
      "45 : 2355.81503635 0.00222\n",
      "46 : 2364.5921586 0.00212\n",
      "47 : 2320.87779693 0.00206\n",
      "48 : 2309.92975581 0.0021\n",
      "49 : 2279.46523343 0.00198\n"
     ]
    }
   ],
   "source": [
    "V_temp = V4\n",
    "W_temp = W4\n",
    "ind = nr.choice(50000,50000, replace = False)\n",
    "loss = loss4\n",
    "misclass = []\n",
    "for j in range(50):\n",
    "    V_temp, W_temp = train_cross_entropy(V_temp, W_temp, tr_img, tr_lb, ind, j, j+1, 0.01 * 0.5*0.5)\n",
    "    loss_temp = calculate_loss(V_temp, W_temp, tr_img, tr_lb, cross_entropy)\n",
    "    mis_temp = misclassification(V_temp, W_temp, tr_img, tr_lb_num)\n",
    "    print(j, ':', loss_temp, mis_temp)\n",
    "    loss = np.append(loss, [loss_temp])\n",
    "    misclass= np.append(misclass, [mis_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V5,W5,loss5 = (V_temp, W_temp, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 2275.27653746 0.00206\n",
      "1 : 2269.01665465 0.00202\n",
      "2 : 2252.78138574 0.0021\n",
      "3 : 2256.78304141 0.00204\n",
      "4 : 2252.4089881 0.00202\n",
      "5 : 2236.27507948 0.00198\n",
      "6 : 2234.35864108 0.00204\n",
      "7 : 2221.62930482 0.0021\n",
      "8 : 2214.89033171 0.00208\n",
      "9 : 2203.72950976 0.00204\n",
      "10 : 2187.5632859 0.002\n",
      "11 : 2199.47764528 0.00204\n",
      "12 : 2186.23753563 0.00202\n",
      "13 : 2165.30236341 0.00202\n",
      "14 : 2159.28772825 0.002\n",
      "15 : 2160.60911268 0.00206\n",
      "16 : 2150.73977013 0.002\n",
      "17 : 2145.58062905 0.00202\n",
      "18 : 2137.59131412 0.00198\n",
      "19 : 2133.06834618 0.00204\n",
      "20 : 2130.28985702 0.0021\n",
      "21 : 2126.15197018 0.00198\n",
      "22 : 2100.87093677 0.00196\n",
      "23 : 2100.6274171 0.002\n",
      "24 : 2088.12451461 0.00198\n",
      "25 : 2080.09991055 0.00206\n",
      "26 : 2062.15391893 0.00196\n",
      "27 : 2068.01374169 0.00198\n",
      "28 : 2056.49964896 0.00186\n",
      "29 : 2043.07786474 0.00168\n",
      "30 : 2055.67890459 0.00184\n",
      "31 : 2031.70050911 0.00176\n",
      "32 : 2011.6799115 0.00168\n",
      "33 : 2031.81337441 0.0017\n",
      "34 : 2019.94121244 0.00166\n",
      "35 : 2001.13926872 0.00156\n",
      "36 : 2001.35871355 0.00144\n",
      "37 : 1979.18396013 0.00152\n",
      "38 : 1966.54892193 0.0015\n",
      "39 : 1983.64282898 0.0015\n",
      "40 : 1962.11679855 0.00156\n",
      "41 : 1931.12764777 0.00148\n",
      "42 : 1946.93085082 0.00148\n",
      "43 : 1942.74532706 0.00142\n",
      "44 : 1927.32890536 0.00144\n",
      "45 : 1901.04281799 0.00148\n",
      "46 : 1885.98637866 0.00156\n",
      "47 : 1881.81102024 0.0015\n",
      "48 : 1876.00236898 0.00138\n",
      "49 : 1879.92691349 0.0014\n"
     ]
    }
   ],
   "source": [
    "V_temp = V5\n",
    "W_temp = W5\n",
    "ind = nr.choice(50000,50000, replace = False)\n",
    "loss = loss5\n",
    "misclass = []\n",
    "for j in range(50):\n",
    "    V_temp, W_temp = train_cross_entropy(V_temp, W_temp, tr_img, tr_lb, ind, j, j+1, 0.01 * 0.5*0.5)\n",
    "    loss_temp = calculate_loss(V_temp, W_temp, tr_img, tr_lb, cross_entropy)\n",
    "    mis_temp = misclassification(V_temp, W_temp, tr_img, tr_lb_num)\n",
    "    print(j, ':', loss_temp, mis_temp)\n",
    "    loss = np.append(loss, [loss_temp])\n",
    "    misclass= np.append(misclass, [mis_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V6,W6,loss6, misclass6 = (V_temp, W_temp, loss, misclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1863.18855106 0.00142\n",
      "1 : 1843.609186 0.00142\n",
      "2 : 1841.00497505 0.00136\n",
      "3 : 1839.06191727 0.00138\n",
      "4 : 1839.90264808 0.00138\n",
      "5 : 1837.09315191 0.00136\n",
      "6 : 1831.52047536 0.00136\n",
      "7 : 1824.48449766 0.00134\n",
      "8 : 1818.8428198 0.0014\n",
      "9 : 1813.37639853 0.00138\n",
      "10 : 1811.2734474 0.0014\n",
      "11 : 1808.59884281 0.0014\n",
      "12 : 1809.87539449 0.0014\n",
      "13 : 1805.65244716 0.0014\n",
      "14 : 1798.58158101 0.00138\n",
      "15 : 1794.25511009 0.00136\n",
      "16 : 1788.72088345 0.00138\n",
      "17 : 1786.21787384 0.00132\n",
      "18 : 1782.86028796 0.00128\n",
      "19 : 1779.26591601 0.00132\n",
      "20 : 1779.15166205 0.00136\n",
      "21 : 1778.38923872 0.00126\n",
      "22 : 1773.21749301 0.00128\n",
      "23 : 1770.26394077 0.00124\n",
      "24 : 1768.51310962 0.0012\n",
      "25 : 1767.07436332 0.0012\n",
      "26 : 1761.91666461 0.00122\n",
      "27 : 1757.76772587 0.00122\n",
      "28 : 1755.04459447 0.00124\n",
      "29 : 1755.38960523 0.00124\n",
      "30 : 1751.24418704 0.00124\n",
      "31 : 1744.63917305 0.0012\n",
      "32 : 1740.77051948 0.00122\n",
      "33 : 1734.822755 0.00124\n",
      "34 : 1732.11887779 0.0012\n",
      "35 : 1729.85687408 0.00126\n",
      "36 : 1726.52989527 0.00124\n",
      "37 : 1720.74226678 0.00128\n",
      "38 : 1717.10749548 0.00128\n",
      "39 : 1711.64893263 0.00124\n",
      "40 : 1708.39282003 0.00124\n",
      "41 : 1705.2824831 0.00124\n",
      "42 : 1704.14530967 0.00126\n",
      "43 : 1702.75101457 0.00124\n",
      "44 : 1707.27921588 0.00118\n",
      "45 : 1708.41991324 0.00122\n",
      "46 : 1691.27156287 0.0012\n",
      "47 : 1686.00887031 0.00118\n",
      "48 : 1681.43329542 0.00114\n",
      "49 : 1676.73003015 0.00112\n"
     ]
    }
   ],
   "source": [
    "V_temp = V6\n",
    "W_temp = W6\n",
    "ind = nr.choice(50000,50000, replace = False)\n",
    "loss = loss6\n",
    "misclass = misclass6\n",
    "for j in range(50):\n",
    "    V_temp, W_temp = train_cross_entropy(V_temp, W_temp, tr_img, tr_lb, ind, j, j+1, 0.01 * 0.5*0.5*0.5)\n",
    "    loss_temp = calculate_loss(V_temp, W_temp, tr_img, tr_lb, cross_entropy)\n",
    "    mis_temp = misclassification(V_temp, W_temp, tr_img, tr_lb_num)\n",
    "    print(j, ':', loss_temp, mis_temp)\n",
    "    loss = np.append(loss, [loss_temp])\n",
    "    misclass= np.append(misclass, [mis_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036799999999999999"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification(V7, W7, add_bias(vd_img), vd_lb_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V7, W7, loss7, misclass7 = V_temp, W_temp, loss, misclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1673.39891164 0.00114\n",
      "1 : 1673.73132343 0.00116\n",
      "2 : 1668.38799214 0.00114\n",
      "3 : 1666.20023313 0.00116\n",
      "4 : 1666.98263246 0.00112\n",
      "5 : 1672.47259482 0.00108\n",
      "6 : 1668.82447881 0.0011\n",
      "7 : 1670.05472661 0.00114\n",
      "8 : 1664.67512736 0.00116\n",
      "9 : 1659.12542647 0.00108\n",
      "10 : 1656.01361218 0.00112\n",
      "11 : 1654.16066225 0.00112\n",
      "12 : 1648.90062829 0.00112\n",
      "13 : 1647.0798692 0.00112\n",
      "14 : 1644.17912072 0.00114\n",
      "15 : 1641.87799619 0.00114\n",
      "16 : 1639.5844865 0.00112\n",
      "17 : 1640.82955209 0.00116\n",
      "18 : 1638.42201023 0.00112\n",
      "19 : 1638.56933917 0.00112\n",
      "20 : 1636.88167151 0.00112\n",
      "21 : 1634.62546983 0.00116\n",
      "22 : 1631.8114599 0.00108\n",
      "23 : 1628.68783636 0.00108\n",
      "24 : 1622.27980808 0.00104\n",
      "25 : 1619.75480139 0.00104\n",
      "26 : 1618.64624012 0.0011\n",
      "27 : 1616.2854415 0.00112\n",
      "28 : 1619.19380151 0.0011\n",
      "29 : 1614.36305919 0.00114\n",
      "30 : 1609.25189574 0.00112\n",
      "31 : 1606.04780794 0.00118\n",
      "32 : 1604.62124476 0.00118\n",
      "33 : 1602.70104739 0.0011\n",
      "34 : 1597.00628172 0.0011\n",
      "35 : 1593.12020112 0.00106\n",
      "36 : 1591.28607763 0.00106\n",
      "37 : 1586.17510919 0.00102\n",
      "38 : 1582.83883289 0.00102\n",
      "39 : 1581.25825146 0.00102\n",
      "40 : 1577.3951074 0.00098\n",
      "41 : 1573.87185023 0.00104\n",
      "42 : 1573.26347109 0.00106\n",
      "43 : 1567.78409674 0.00104\n",
      "44 : 1568.60126585 0.00106\n",
      "45 : 1560.14872836 0.001\n",
      "46 : 1563.07919872 0.00096\n",
      "47 : 1564.99413366 0.00098\n",
      "48 : 1555.93541238 0.00098\n",
      "49 : 1555.4578429 0.001\n"
     ]
    }
   ],
   "source": [
    "V_temp = V7\n",
    "W_temp = W7\n",
    "ind = nr.choice(50000,50000, replace = False)\n",
    "loss = loss7\n",
    "misclass = misclass7\n",
    "for j in range(50):\n",
    "    V_temp, W_temp = train_cross_entropy(V_temp, W_temp, tr_img, tr_lb, ind, j, j+1, 0.01 * 0.5*0.5*0.5)\n",
    "    loss_temp = calculate_loss(V_temp, W_temp, tr_img, tr_lb, cross_entropy)\n",
    "    mis_temp = misclassification(V_temp, W_temp, tr_img, tr_lb_num)\n",
    "    print(j, ':', loss_temp, mis_temp)\n",
    "    loss = np.append(loss, [loss_temp])\n",
    "    misclass= np.append(misclass, [mis_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036799999999999999"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V8, W8, loss8, misclass8 = V_temp, W_temp, loss, misclass\n",
    "misclassification(V8, W8, add_bias(vd_img), vd_lb_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036400000000000002"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification(V5, W5, add_bias(vd_img), vd_lb_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_kag_cross = predict(V8, W8, add_bias(ts_img))\n",
    "pred_num_cross = np.argmax(pred_kag_cross,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 2, ..., 4, 7, 2])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_num_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_cross = np.asarray([[i+1, pred_num_cross[i]] for i in np.arange(10000)])\n",
    "np.savetxt('pred_cross.csv',pred_cross,fmt = '%1.u' , delimiter = ',', header = 'Id,Category',comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 10000)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.44160482e-03,   5.22016001e-06,   1.04723061e-03, ...,\n",
       "          4.94551843e-05,   4.58721870e-02,   1.61482523e-03],\n",
       "       [  6.82668517e-04,   2.43801874e-07,   6.31688775e-02, ...,\n",
       "          1.16601674e-05,   9.39459726e-08,   4.43591382e-03],\n",
       "       [  6.57341044e-04,   3.75681877e-06,   1.96056978e-02, ...,\n",
       "          1.88533313e-06,   8.64890747e-06,   5.63097725e-07],\n",
       "       ..., \n",
       "       [  3.35523814e-06,   3.97528479e-05,   8.69212672e-05, ...,\n",
       "          5.34392809e-01,   8.24591765e-07,   1.32949370e-06],\n",
       "       [  7.41625673e-03,   1.56300075e-05,   5.49985906e-05, ...,\n",
       "          9.96520548e-01,   4.97298308e-04,   4.59268457e-02],\n",
       "       [  9.72882343e-07,   8.73044788e-03,   7.67536801e-02, ...,\n",
       "          5.25550347e-03,   3.83360121e-07,   1.04308173e-06]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_kag_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
