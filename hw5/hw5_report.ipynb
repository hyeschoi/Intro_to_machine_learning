{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS189 Spring 2016: Introduction to Machine Learning\n",
    "\n",
    "## SID : 23274190 / Name: Hye Soo Choi\n",
    "\n",
    "### Decision Trees for Classification\n",
    "In this homework, we will implement decision trees and random forests for classification\n",
    "on 2 datasets: \n",
    " 1. the spam data \n",
    " 2. a census income dataset \n",
    " \n",
    " \n",
    "to predict whether or not a person makes over 50k in income. \n",
    "In lectures, we were given a basic introduction to decision trees and how such trees\n",
    "are trained. We were also introduced to random forests and boosting algorithms. We have freedom to research different decision tree techniques online. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from statistics import mode\n",
    "from scipy import stats\n",
    "from sklearn.cross_validation import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_rawdata = sio.loadmat('./spam-dataset/spam_data.mat')\n",
    "census_rawdata = pd.read_csv('./census_data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "sp_test = spam_rawdata['test_data']\n",
    "sp_dataf = spam_rawdata['training_data']\n",
    "sp_datav = spam_rawdata['training_labels'][0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing : Census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "census_rawdata.values.shape\n",
    "census_fv = census_rawdata.values[:,0:14]\n",
    "census_lb = census_rawdata.values[:,14]\n",
    "census_test = np.array(pd.read_csv('./census_data/test_data.csv').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(census_fv[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that economic welfare of the native country can be assessed by its GDP per capita, we convert the native country(column 13) into its GDP per capita. Also, we deleted the 3rd column, education, since it is redundant considering the next column 'education number' also indicates education level. We think that the education levels can be treated as ordered categorical values since in general sense, the higher education a person   and this removal would facilitate the overal analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(14):\n",
    "    fv = census_fv[:,i]\n",
    "\n",
    "    if type(fv[0]) == str or type(fv[0]) == np.str_:\n",
    "        values = list(Counter(fv).keys())\n",
    "        num = len(values)\n",
    "        count= [0 for m in range(num)]\n",
    "        count1 = [0 for m in range(num)]\n",
    "        for j in range(len(fv)):\n",
    "            for k in range(num):\n",
    "                if fv[j] == values[k] :\n",
    "                    count[k] += 1\n",
    "                    count1[k] += 1\n",
    "        prop = np.array([count1[l]/count[l] for l in range(num)])\n",
    "        def compare_prop(x):\n",
    "            return prop[x]\n",
    "        \n",
    "        new_values = sorted(list(range(num)), key = compare_prop)\n",
    "\n",
    "        dic = {values[m]: new_values[m] for m in range(num)}\n",
    "        new_fv = [dic[m] for m in fv]\n",
    "        census_fv[:,i] = new_fv\n",
    "        \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Spam data\n",
    "- Over-sample :\n",
    "\n",
    "\n",
    "Since spam data is somewhat skewed in that the number of spam is much bigger than the number of ham. To handle this data, we will over-sample the given data and therefore achieve a more balanced class distributions by replicating examples of the minority class.\n",
    "\n",
    "- Transform each element into proportion of the numbers of featured word in the total numbers in email.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_zero_one(x):\n",
    "    1 * (x > 0)\n",
    "    \n",
    "def convert_to_prop(x):\n",
    "    total = sum(x)\n",
    "    if total == 0:\n",
    "        total = 1\n",
    "    return [x[i]/total for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_feat = []\n",
    "for i in range(len(sp_datav)):\n",
    "    new_feat.append([sum(sp_dataf[i,:])])\n",
    "sp_dataf_ext = np.append(sp_dataf, new_feat, axis = 1)\n",
    "\n",
    "new_feat = []\n",
    "for i in range(sp_test.shape[0]):\n",
    "    new_feat.append([sum(sp_test[i,:])])\n",
    "sp_test_ext = np.append(sp_test, new_feat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_dataf_prop = []\n",
    "sp_test_prop = []\n",
    "for i in range(len(sp_datav)):\n",
    "    sp_dataf_prop.append(convert_to_prop(sp_dataf[i,:]))\n",
    "sp_dataf_prop = np.array(sp_dataf_prop)\n",
    "\n",
    "for i in range(sp_test.shape[0]):\n",
    "    sp_test_prop.append(convert_to_prop(sp_test[i,:]))\n",
    "sp_test_prop = np.array(sp_test_prop)\n",
    "\n",
    "\n",
    "spam_ind = np.array([i for i in range(len(sp_datav)) if sp_datav[i] == 1])\n",
    "over_ind = np.append(range(len(sp_datav)), spam_ind)\n",
    "sp_overf_ext = sp_dataf_ext[over_ind, :]\n",
    "sp_overv = sp_datav[over_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5857, 33)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_test_ext.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_ind = np.array([i for i in range(len(sp_datav)) if sp_datav[i] == 1])\n",
    "over_ind = np.append(range(len(sp_datav)), spam_ind)\n",
    "sp_overf = sp_dataf[over_ind, :]\n",
    "sp_overv = sp_datav[over_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values =  [1,2,3,4,5,6,6,7,8,9,7,6,5,4,3,2,1,10]\n",
    "labels = [0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,0]\n",
    "counter = Counter(values)\n",
    "uvalues = sorted(counter.keys())\n",
    "ufreq = [counter[i] for i in uvalues]\n",
    "pair = [[values[i], labels[i]] for i in range(len(values))]\n",
    "sort_pair = sorted(pair, key= itemgetter(0))\n",
    "sort_label = []\n",
    "count = 0\n",
    "risk = 0\n",
    "\n",
    "          \n",
    "for i in range(len(uvalues)):\n",
    "    sort_label.append([sort_pair[j][1]  for j in range(count, count + ufreq[i])])\n",
    "    count = count + ufreq[i]\n",
    "                \n",
    "left_labels = []\n",
    "right_labels = sum(sort_label, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_ind = np.array([i for i in range(len(census_lb)) if census_lb[i] == 1])\n",
    "over_ind = np.append(range(len(census_lb)), np.append(non_ind, np.append(non_ind, non_ind)))\n",
    "cs_overf = census_fv[over_ind, :]\n",
    "cs_overv = census_lb[over_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value\n",
    "\n",
    "We implement within our decision tree functionality to handle missing feature values based on the current node. More precisely, we infer missing values based on the mode of the feature values of data points sorted to the current\n",
    "node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for DecisionTree class\n",
    "\n",
    "#### Choosing categorical data\n",
    "\n",
    "We keep the categories as strings. Then we implement functionality in decision trees to determine split rules based\n",
    "on the subsets of categorical variables that maximizes information gain.\n",
    "\n",
    "#### stopping condition\n",
    "\n",
    "We stop growing tree when a node meets any of the following conditions:\n",
    "\n",
    " 1. its depth of tree is greater than the max depth,\n",
    " 2. the number of data point in a node is less than 10,\n",
    " 3. more than 95% of labels in the node are of the same label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def hist_labels(labels):\n",
    "    def f(n):\n",
    "        if n == 1:\n",
    "            return sum(labels)\n",
    "        else:\n",
    "            return len(labels) - sum(labels)\n",
    "    return f\n",
    "\n",
    "def powerset(orig, newset):\n",
    "    if orig == []:\n",
    "        return [newset]\n",
    "    else:\n",
    "        res = []\n",
    "        for s in powerset(orig[1:], newset + [orig[0]]):\n",
    "            res.append(s)\n",
    "        for s in powerset(orig[1:], newset):\n",
    "            res.append(s)\n",
    "        return res\n",
    "    \n",
    "def entropy(p):\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return - p * np.log(p)/np.log(2)\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, data, labels, limit):\n",
    "        self.root = None\n",
    "        self.values = list(Counter(labels).keys())\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.limit = limit\n",
    "        self.prune_count = 0\n",
    "        self.node_count = 0 \n",
    "        self.threshold = 4/6\n",
    "\n",
    "    \n",
    "    def impurity(self, left_label_hist, right_label_hist):\n",
    "        '''A method that takes in the result of a split: two histograms \n",
    "        (a histogram is a mapping from label values to their frequencies) \n",
    "        that count the frequencies of labels on the \"left\" and \"right\" side of that split. \n",
    "        The method calculates and outputs a scalar value representing the impurity \n",
    "        (i.e. the \"badness\") of the specified split on the input data.'''\n",
    "        \n",
    "        left_freq = [left_label_hist(i) for i in self.values]\n",
    "        right_freq = [right_label_hist(i) for i in self.values]\n",
    "        \n",
    "        left_total = sum(left_freq)\n",
    "        right_total = sum(right_freq)\n",
    "        \n",
    "        left_prob = [i/ left_total for i in left_freq]\n",
    "        right_prob = [ i/ right_total for i in right_freq]\n",
    "        \n",
    "        left_loss = sum([entropy(p) for p in left_prob])\n",
    "        right_loss = sum([entropy(p) for p in right_prob])\n",
    "        \n",
    "        return (left_total * left_loss + right_total * right_loss)/ (left_total + right_total)\n",
    "    \n",
    "    \n",
    "    def gini_impurity(self, left_label_hist, right_label_hist):\n",
    "        '''A method that takes in the result of a split: two histograms \n",
    "        (a histogram is a mapping from label values to their frequencies) \n",
    "        that count the frequencies of labels on the \"left\" and \"right\" side of that split. \n",
    "        The method calculates and outputs a scalar value representing the impurity \n",
    "        (i.e. the \"badness\") of the specified split on the input data.'''\n",
    "        \n",
    "        left_freq = [left_label_hist(i) for i in self.values]\n",
    "        right_freq = [right_label_hist(i) for i in self.values]\n",
    "        \n",
    "        left_total = sum(left_freq)\n",
    "        right_total = sum(right_freq)\n",
    "        \n",
    "        left_prob = [i/ left_total for i in left_freq]\n",
    "        right_prob = [ i/ right_total for i in right_freq]\n",
    "        \n",
    "        left_loss = sum([p*(1-p) for p in left_prob])\n",
    "        right_loss = sum([p*(1-p) for p in right_prob])\n",
    "        \n",
    "        return (left_total * left_loss + right_total * right_loss)/ (left_total + right_total)\n",
    "    \n",
    "    def segmenter(self, data, labels): \n",
    "        '''A method that takes in data and labels. When called, it finds the best split rule \n",
    "        for a Node using the impurity measure and input data. There are many different types of \n",
    "        segmenters you might implement, each with a different method of choosing a threshold. \n",
    "        The usual method is exhaustively trying lots of different threshold values from the data \n",
    "        and choosing the combination of split feature and threshold with the lowest impurity value. \n",
    "        The final split rule uses the split feature with the lowest impurity value and the threshold chosen by the \n",
    "        segmenter. \n",
    "        '''\n",
    "        \n",
    "        counter = Counter(labels)\n",
    "        keys = list(counter.keys())\n",
    "        freq = list(counter.values())\n",
    "        \n",
    "        n = len(labels)\n",
    "        risk = 0\n",
    "\n",
    "        if freq[0]/n == 1:\n",
    "            return keys[0]\n",
    "\n",
    "        \n",
    "        elif sum(freq) < len(self.labels)/2000:\n",
    "            if sum(labels) / len(labels) > self.threshold:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "        else:\n",
    "            num_feat = data.shape[1]\n",
    "\n",
    "            for i in range(num_feat) :\n",
    "                feat_values = data[ :,i]\n",
    "                counter_fvalues = Counter(feat_values)\n",
    "                fvkeys = list(counter_fvalues.keys())\n",
    "                fvfreq = list(counter_fvalues.values())\n",
    "                if len(fvkeys) == 1:\n",
    "                    continue\n",
    "                elif type(feat_values[0]) == str or type(feat_values[0]) == np.str_ :\n",
    "                    temp = self.segmenter_str(feat_values, labels)\n",
    "                else:\n",
    "                    temp = self.segmenter_int(feat_values, labels)\n",
    "                    \n",
    "                temp_segment = temp[0]\n",
    "                temp_risk = temp[1]\n",
    "                if risk == 0:\n",
    "                    risk = temp_risk\n",
    "                    segment = [i, temp_segment]\n",
    "                elif risk > temp_risk:\n",
    "                    segment = [i, temp_segment]\n",
    "                    risk = temp_risk\n",
    "            if risk == 0:\n",
    "                if sum(labels)/len(labels) > self.threshold:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "            else:\n",
    "                return segment\n",
    "            \n",
    "                \n",
    "    def segmenter_int(self, values, labels):\n",
    "        missing_ind = [i for i in range(len(values)) if values[i] == '?']\n",
    "        nomis_values = [values[j] for j in range(len(values)) if j not in missing_ind]\n",
    "        mode = np.mean(nomis_values)\n",
    "        for i in missing_ind:\n",
    "            values[i] = mode\n",
    "        \n",
    "        counter = Counter(values)\n",
    "        uvalues = sorted(counter.keys())\n",
    "        ufreq = [counter[i] for i in uvalues]\n",
    "        pair = [[values[i], labels[i]] for i in range(len(values))]\n",
    "        sort_pair = sorted(pair, key= itemgetter(0))\n",
    "        sort_label = []\n",
    "        count = 0\n",
    "        risk = 0\n",
    "\n",
    "          \n",
    "        for i in range(len(uvalues)):\n",
    "            sort_label.append([sort_pair[j][1]  for j in range(count, count + ufreq[i])])\n",
    "            count = count + ufreq[i]\n",
    "                \n",
    "        left_labels = []\n",
    "        right_labels = sum(sort_label, [])\n",
    "        for i in range(len(uvalues)-1):\n",
    "            left_labels = left_labels + sort_label[i]\n",
    "            right_labels = right_labels[ufreq[i]:]\n",
    "        \n",
    "            left_histogram = hist_labels(left_labels)\n",
    "            right_histogram = hist_labels(right_labels)\n",
    "            temp_risk = self.impurity(left_histogram, right_histogram)\n",
    "            \n",
    "            if i == 0 :\n",
    "                risk = temp_risk\n",
    "                split = (uvalues[i] + uvalues[i+1])/2\n",
    "            elif risk > temp_risk:\n",
    "                risk = temp_risk\n",
    "                split = (uvalues[i] + uvalues[i+1])/2\n",
    "            \n",
    "        def split_rule(x):\n",
    "            if x == -1:\n",
    "                return split\n",
    "            else:\n",
    "                return x > split\n",
    "        \n",
    "        return [split_rule, risk]\n",
    "                \n",
    "        \n",
    "    def segmenter_str(self, values, labels):\n",
    "        missing_ind = [i for i in range(len(values)) if values[i] == '?']\n",
    "        nomis_values = [values[j] for j in range(len(values)) if j not in missing_ind]\n",
    "        mode = max(set(nomis_values), key=nomis_values.count)\n",
    "        for i in missing_ind:\n",
    "            values[i] = mode\n",
    "\n",
    "            \n",
    "        counter = Counter(values)\n",
    "        uvalues = sorted(counter.keys())\n",
    "        ufreq = [counter[i] for i in uvalues]\n",
    "        pair = [[values[i], labels[i]] for i in range(len(values))]\n",
    "        sort_pair = sorted(pair, key= itemgetter(0))\n",
    "        sort_label = []\n",
    "        count = 0\n",
    "        \n",
    "        for i in range(len(uvalues)):\n",
    "            sort_label.append([sort_pair[j][1]  for j in range(count, count + ufreq[i])])\n",
    "            count = count + ufreq[i]\n",
    "            \n",
    "        count = 0      \n",
    "        left_labels = []\n",
    "        right_labels = []\n",
    "        risk = 0\n",
    "        power_values = [l for l in powerset([j for j in range(len(uvalues))],[]) \n",
    "                        if len(l) <= len(uvalues)/2  and len(l) > 0 ]\n",
    "        \n",
    "        \n",
    "        for indice in power_values:\n",
    "      \n",
    "            left_labels = sum([sort_label[h] for h in indice],[])\n",
    "            right_labels = sum([sort_label[h] for h in range(len(uvalues)) if h not in indice],[])\n",
    "        \n",
    "            left_histogram = hist_labels(left_labels)\n",
    "            right_histogram = hist_labels(right_labels)\n",
    "            temp_risk = self.impurity(left_histogram, right_histogram)\n",
    "\n",
    "            if risk == 0 :\n",
    "                risk = temp_risk\n",
    "                split = [uvalues[i] for i in indice]\n",
    "            elif risk > temp_risk:\n",
    "                risk = temp_risk\n",
    "                split = [uvalues[i] for i in indice]\n",
    "        def split_rule(x):\n",
    "            if x == -1:\n",
    "                return split\n",
    "            else:\n",
    "                return x in split\n",
    "        \n",
    "        return [split_rule, risk]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self, data, labels):\n",
    "        \n",
    "\n",
    "        def construct_node(cdata,clabels, depth):\n",
    "\n",
    "\n",
    "            \n",
    "            counter = Counter(clabels)\n",
    "            ulabel = list(counter.keys())\n",
    "            self.node_count += 1\n",
    "            \n",
    "            if len(ulabel)<=1:\n",
    "                n = len(clabels)\n",
    "                    \n",
    "                return Node(label = ulabel[0], impurity = 0, num = n)\n",
    "            else:\n",
    "                segment = self.segmenter(cdata, clabels)\n",
    "           \n",
    "            \n",
    "            if type(segment) != list:\n",
    "                n = len(clabels)\n",
    "                if segment == 0:\n",
    "                    imp = len([i for i in range(len(clabels)) if clabels[i] != segment])/ n\n",
    "                else:\n",
    "                    imp =  len([i for i in range(len(clabels)) if clabels[i] != segment])/ n\n",
    "                \n",
    "                return Node(label = segment, impurity = imp, num = n)\n",
    "            \n",
    "            elif depth > self.limit:\n",
    "                p = sum(clabels)/len(clabels)\n",
    "                n = len(clabels)\n",
    "                \n",
    "                if p > self.threshold:\n",
    "                    temp_label = 1\n",
    "                    imp = ( len([i for i in range(len(clabels)) if clabels[i] != temp_label]))/ n\n",
    "                else:\n",
    "                    temp_label = 0\n",
    "                    imp = len([i for i in range(len(clabels)) if clabels[i] != temp_label])/ n\n",
    "                \n",
    "                return Node(label = temp_label, impurity = imp, num=n)\n",
    "\n",
    "            else: \n",
    "                split_rule = segment[1]\n",
    "                split_fv = cdata[: , segment[0]]\n",
    "                missing_ind = [i for i in range(len(split_fv)) if split_fv[i] == '?']\n",
    "                nomis_values = [split_fv[j] for j in range(len(split_fv)) if j not in missing_ind]\n",
    "                mode = np.mean(nomis_values)\n",
    "                for i in missing_ind:\n",
    "                    split_fv[i] = mode\n",
    "\n",
    "\n",
    "                split_cond = np.array([split_rule(i) for i in split_fv])\n",
    "                left_data = cdata[split_cond,:]\n",
    "                left_labels = clabels[split_cond]\n",
    "                right_data = cdata[~ split_cond,:]\n",
    "                right_labels = clabels[~ split_cond]\n",
    "                \n",
    "                p = sum(clabels) / len(clabels)\n",
    "                \n",
    "                n = len(clabels)\n",
    "                if p > self.threshold :\n",
    "                    temp_label = 1\n",
    "                    imp = (len([i for i in range(len(clabels)) if clabels[i] != temp_label]))/ n\n",
    "                else:\n",
    "                    temp_label = 0\n",
    "                    imp = len([i for i in range(len(clabels)) if clabels[i] != temp_label])/ n\n",
    "                return Node(split_rule= segment, left = construct_node(left_data, left_labels, depth+1),\n",
    "                            right = construct_node(right_data, right_labels, depth+1), impurity = imp, num = n,\n",
    "                           temp_label = temp_label)\n",
    "            \n",
    "        self.root = construct_node(data, labels, 0)\n",
    "        \n",
    "    def predict(self, data):\n",
    "        n = data.shape[0]\n",
    "        res = [-1 for i in range(n)]\n",
    "        def test(cdata, current, ind):\n",
    "            \n",
    "            if len(ind) == 0:\n",
    "                return\n",
    "                \n",
    "            elif current.label != None:\n",
    "                for i in ind:\n",
    "                    res[i] = current.label\n",
    "            else: \n",
    "                current_rule = current.split_rule[1]\n",
    "                current_index = current.split_rule[0]\n",
    "                fv = cdata[:, current_index]\n",
    "                missing_ind = [i for i in range(len(fv)) if fv[i] == '?']\n",
    "                nomis_values = [fv[j] for j in range(len(fv)) if j not in missing_ind]\n",
    "                mode = max(set(nomis_values), key=nomis_values.count)\n",
    "                for i in missing_ind:\n",
    "                    fv[i] = mode          \n",
    "                \n",
    "                split_cond = np.array([current_rule(i) for i in fv])\n",
    "                left_data = cdata[split_cond, :]\n",
    "                right_data = cdata[~split_cond, :]\n",
    "                left_ind = ind[split_cond]\n",
    "                right_ind = ind[~split_cond]\n",
    "                if len(left_ind) > 0:\n",
    "                    test(left_data, current.left, left_ind)\n",
    "                if len(right_ind) > 0:\n",
    "                    test(right_data, current.right, right_ind)\n",
    "        test(data, self.root, np.array(list(range(n))))\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def prune(self, alpha):\n",
    "        \n",
    "\n",
    "        def prune_node(current):\n",
    "            if current.left.label != None and current.right.label != None:\n",
    "     \n",
    "                \n",
    "                \n",
    "                post_error = (current.left.num * current.left.impurity \n",
    "                              + current.right.num * current.right.impurity)/ current.num\n",
    "\n",
    "                if current.impurity < post_error + alpha:\n",
    "                    current.label =  current.temp_label\n",
    "                    current.left = None\n",
    "                    current.right = None\n",
    "                    self.prune_count += 1\n",
    "                    self.node_count -= 1\n",
    "                    \n",
    "                    \n",
    "        def prune_tree(current):\n",
    "            if current.num == 0:\n",
    "                return\n",
    "            elif current.label == None:       \n",
    "                prune_tree(current.left)\n",
    "                prune_tree(current.right)\n",
    "                prune_node(current)\n",
    "                \n",
    "\n",
    "        prune_tree(self.root)\n",
    "        print(self.prune_count)\n",
    "        print(self.node_count)\n",
    "\n",
    "                  \n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, split_rule = None, left = None, right = None, label = None, impurity = None, \n",
    "                 temp_label = None, num = 0):\n",
    "        self.split_rule = split_rule\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.label = label\n",
    "        self.impurity = impurity\n",
    "        self.temp_label = temp_label\n",
    "        self.num = num\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation to determine the hyperparameter for pruning\n",
    "\n",
    "Starting from each leaf, if the decrease in impurity, which we gain as a result of having the parent node splitted, is less than $\\alpha$, then we choose to prune the subtree that has the parent node as its root. To determine best value of $\\alpha $, we use 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(sp_overv), n_folds=5)\n",
    "def cv_pruning(alpha):\n",
    "    test_error = 0 \n",
    "\n",
    "    for train_index, test_index in kf:\n",
    "    \n",
    "        X_train, X_test = sp_overf_ext[train_index, : ], sp_overf_ext[test_index, :]\n",
    "        y_train, y_test = sp_overv[train_index], sp_overv[test_index]\n",
    "        sp_tree = DecisionTree(X_train, y_train, 50)\n",
    "        sp_tree.train(X_train, y_train)\n",
    "        sp_tree.prune(alpha)\n",
    "        sp_predcv =sp_tree.predict(X_test)\n",
    "        count = 0\n",
    "        for j in range(len(y_test)):\n",
    "            if y_test[j] != sp_predcv[j]:\n",
    "                count += 1\n",
    "        test_error += count/len(y_test)\n",
    "    \n",
    "    return test_error/5\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "672\n",
      "116\n",
      "591\n",
      "135\n",
      "556\n",
      "132\n",
      "597\n",
      "123\n",
      "680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2291581175704283"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_pruning(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "667\n",
      "138\n",
      "569\n",
      "138\n",
      "553\n",
      "137\n",
      "592\n",
      "136\n",
      "667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2335044837131996"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_pruning(5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "738\n",
      "154\n",
      "653\n",
      "187\n",
      "612\n",
      "212\n",
      "615\n",
      "182\n",
      "715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22766189938738496"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_pruning(1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation to determine the hyperparameter for pruning with census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(census_lb), n_folds=5)\n",
    "def cv_pruning_cs(alpha):\n",
    "    test_error = 0 \n",
    "\n",
    "    for train_index, test_index in kf:\n",
    "    \n",
    "        X_train, X_test = census_fv[train_index, : ], census_fv[test_index, :]\n",
    "        y_train, y_test = census_lb[train_index], census_lb[test_index]\n",
    "        cs_tree = DecisionTree(X_train, y_train, 10)\n",
    "        cs_tree.train(X_train, y_train)\n",
    "        cs_tree.prune(alpha)\n",
    "        cs_predcv =cs_tree.predict(X_test)\n",
    "        count = 0\n",
    "        for j in range(len(y_test)):\n",
    "            if y_test[j] != cs_predcv[j]:\n",
    "                count += 1\n",
    "        test_error += count/len(y_test)\n",
    "    \n",
    "    return test_error/5\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_pruning_cs(1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of cross-validation, we learn the best $\\alpha$ value is $10^{-1}$ for spam data and for census data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission to Kaggle\n",
    "With the best $\\alpha$ value, we trained a single decision tree and test the model on the test data. This achieved for spam data and for census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "653\n"
     ]
    }
   ],
   "source": [
    "sp_final_tree = DecisionTree(sp_overf_ext, sp_overv, 50)\n",
    "sp_final_tree.train(sp_overf_ext, sp_overv)\n",
    "sp_final_tree.prune(1e-2)\n",
    "dt_pred = sp_final_tree.predict(sp_test_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5857, 32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_test_prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1715"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_pred = sp_final_tree.predict(sp_test_ext)\n",
    "sum(dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_pred_txt = np.asarray([[i+1, dt_pred[i]] for i in np.arange(5857)])\n",
    "np.savetxt('dt_sp_pred4.csv', dt_pred_txt, fmt = '%1.u' , delimiter = ',', header = 'Id,Category',comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs_final_tree = DecisionTree(census_fv, census_lb, 500)\n",
    "cs_final_tree.train(census_fv, census_lb)\n",
    "cs_final_tree.prune(1e-2)\n",
    "cs_pred = cs_final_tree.predict(census_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs_pred_txt = np.asarray([[i+1, cs_pred[i]] for i in np.arange(5857)])\n",
    "np.savetxt('cs_pred.csv', cs_pred_txt, fmt = '%1.u' , delimiter = ',', header = 'Id,Category',comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.5\n",
      "13\n",
      "9.0\n",
      "13\n",
      "10.0\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(sp_final_tree.root.split_rule[1](-1))\n",
    "print(sp_final_tree.root.split_rule[0])\n",
    "print(sp_final_tree.root.right.split_rule[1](-1))\n",
    "print(sp_final_tree.root.right.split_rule[0])\n",
    "print(sp_final_tree.root.right.right.split_rule[1](-1))\n",
    "print(sp_final_tree.root.right.right.split_rule[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split conditions:\n",
    "\n",
    "For spam data,\n",
    "\n",
    "1. 9th feature > 0.0\n",
    "2. 3rd feature > 0.0\n",
    "3. 23rd feature > 0.0\n",
    "\n",
    "were the first three conditions that splits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_pred_txt = np.asarray([[i+1, dt_pred[i]] for i in np.arange(5857)])\n",
    "np.savetxt('dt_sp_pred.csv', dt_pred_txt, fmt = '%1.u' , delimiter = ',', header = 'Id,Category',comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, 1, 1])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([1,2,2,0,0])\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_test = [1*(pred[i] > 50) for i in range(5857)]\n",
    "sp_pred = np.asarray([[i+1, sp_test[i]] for i in np.arange(5857)])\n",
    "np.savetxt('sp_test2.csv', sp_pred, fmt = '%1.u' , delimiter = ',', header = 'Id,Category',comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test2 = DecisionTree(census_fv, census_lb, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clabels = np.array([1,1,1,1,1,1,4,4,5,2,2,2,2,2,2])\n",
    "stats.mode(clabels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cs_pred =[0 for i in range(16118)]\n",
    "for i in range(1):\n",
    "    id0 = np.random.choice(census_fv.shape[0], 3000, replace = True)\n",
    "    test2.train(census_fv[id0, :], census_lb[id0])\n",
    "    pred0 = test2.predict(census_test)\n",
    "    cs_pred = [(cs_pred[i] + pred0[i]) for i in range(16118)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "0\n",
      "0\n",
      "18\n",
      "4\n",
      "['Married-AF-spouse']\n"
     ]
    }
   ],
   "source": [
    "print(test2.root.split_rule[1](-1))\n",
    "print(test2.root.split_rule[0])\n",
    "print(test2.root.left.split_rule[0])\n",
    "\n",
    "print(test2.root.left.split_rule[1](-1))\n",
    "print(test2.root.left.left.split_rule[0])\n",
    "\n",
    "print(test2.root.left.left.split_rule[1](-1))\n",
    "\n",
    " def prune(self, data, labels, alpha):\n",
    "\n",
    "        def prune_node(current, cdata, clabels):\n",
    "            if current.left.label != None and current.right.label != None:\n",
    "     \n",
    "                current_rule = current.split_rule[1]\n",
    "                current_index = current.split_rule[0]\n",
    "                fv = cdata[:, current_index]\n",
    "                missing_ind = [i for i in range(len(fv)) if fv[i] == '?']\n",
    "                nomis_values = [fv[j] for j in range(len(fv)) if j not in missing_ind]\n",
    "                mode = max(set(nomis_values), key=nomis_values.count)\n",
    "                for i in missing_ind:\n",
    "                    fv[i] = mode          \n",
    "                \n",
    "                split_cond = np.array([current_rule(i) for i in fv])\n",
    "                left_data = cdata[split_cond, :]\n",
    "                right_data = cdata[~split_cond, :]\n",
    "                left_labels = clabels[split_cond]\n",
    "                right_labels = clabels[~split_cond]\n",
    "                left_hist = hist_labels(left_labels)\n",
    "                right_hist = hist_labels(right_labels)\n",
    "                \n",
    "                \n",
    "\n",
    "                if current_error < post_error:\n",
    "                    current.label = stats.mode(clabels)[0][0]\n",
    "                    current.left = None\n",
    "                    current.right = None\n",
    "                    \n",
    "        def prune_tree(current, cdata, clabels):\n",
    "            if len(clabels) == 0:\n",
    "                return\n",
    "            elif current.label == None:\n",
    "                \n",
    "            \n",
    "                current_rule = current.split_rule[1]\n",
    "                current_index = current.split_rule[0]\n",
    "                fv = cdata[:, current_index]\n",
    "                missing_ind = [i for i in range(len(fv)) if fv[i] == '?']\n",
    "                nomis_values = [fv[j] for j in range(len(fv)) if j not in missing_ind]\n",
    "                mode = max(set(nomis_values), key=nomis_values.count)\n",
    "                for i in missing_ind:\n",
    "                    fv[i] = mode          \n",
    "                \n",
    "                split_cond = np.array([current_rule(i) for i in fv])\n",
    "                left_data = cdata[split_cond, :]\n",
    "                right_data = cdata[~split_cond, :]\n",
    "                left_labels = clabels[split_cond]\n",
    "                right_labels = clabels[~split_cond]\n",
    "                prune_tree(current.left, left_data, left_labels)\n",
    "                prune_tree(current.right, right_data, right_labels)\n",
    "                prune_node(current, cdata, clabels)\n",
    "        \n",
    "        prune_tree(self.root,data,labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs_test = [1*(cs_pred[i] > 0) for i in range(16118)]\n",
    "cs_pred_ = np.asarray([[i+1, cs_test[i]] for i in np.arange(16118)])\n",
    "np.savetxt('cs_test1.csv', cs_pred_, fmt = '%1.u' , delimiter = ',', header = 'Id,Category',comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle score\n",
    "This results in Kaggle score 0.6837 for spam data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
